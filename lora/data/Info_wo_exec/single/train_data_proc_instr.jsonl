{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: POWGEN\nQ: I need to rerun the processing for my POWGEN data. Give me some information.\nA: On POWGEN, the autoreduction routine is controlled through parameter files located at dedicated places. Instructions for populating those configuration files can be found here, `https://powder.ornl.gov/auto_reduce/powgen_auto.html`. There are two places where we can change the parameters. One is in the POWGEN shared folder (i.e., the `central` config, as detailed in the link) and the other is in the user experiment directory. Users are supposed to only touch the user-level configuration file. The logic about which one takes priority is set in the `central` config for which the information can be found in the link. The user-level config file can be found at `/SNS/PG3/IPTS-xxxxx/shared/autoreduce/auto_params.json`. Once changes are made to the configuration file (either the `central` one or the user-level one), data can be processed in a batch, with the `all_pg3` utility, like `all_pg3 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`.\n\nWith the autoreduction routine, an `XML` file would also be saved, which can be later imported into the GUI for POWGEN data reduction inside `Mantid Workbench`. The `XML` file would be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`. To use it, log in the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and type `mantidworkbench`. Inside the interface, go to `Interfaces` in the menu, and further go to `Diffraction` => `Powder Diffraction Reduction` to launch the GUI for POWGEN data processing. There, we go to `File` => `Open`, and look for the saved `XML` file to load it into the GUI. Then we can make changes as needed and click on the `Reduce` button to process the data."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: POWGEN\nQ: I want to reprocess my POWGEN data.\nA: On POWGEN, the autoreduction routine is controlled through parameter files located at dedicated places. Instructions for populating those configuration files can be found here, `https://powder.ornl.gov/auto_reduce/powgen_auto.html`. There are two places where we can change the parameters. One is in the POWGEN shared folder (i.e., the `central` config, as detailed in the link) and the other is in the user experiment directory. Users are supposed to only touch the user-level configuration file. The logic about which one takes priority is set in the `central` config for which the information can be found in the link. The user-level config file can be found at `/SNS/PG3/IPTS-xxxxx/shared/autoreduce/auto_params.json`. Once changes are made to the configuration file (either the `central` one or the user-level one), data can be processed in a batch, with the `all_pg3` utility, like `all_pg3 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`.\n\nWith the autoreduction routine, an `XML` file would also be saved, which can be later imported into the GUI for POWGEN data reduction inside `Mantid Workbench`. The `XML` file would be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`. To use it, log in the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and type `mantidworkbench`. Inside the interface, go to `Interfaces` in the menu, and further go to `Diffraction` => `Powder Diffraction Reduction` to launch the GUI for POWGEN data processing. There, we go to `File` => `Open`, and look for the saved `XML` file to load it into the GUI. Then we can make changes as needed and click on the `Reduce` button to process the data."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: POWGEN\nQ: How do I rerun POWGEN data processing?\nA: On POWGEN, the autoreduction routine is controlled through parameter files located at dedicated places. Instructions for populating those configuration files can be found here, `https://powder.ornl.gov/auto_reduce/powgen_auto.html`. There are two places where we can change the parameters. One is in the POWGEN shared folder (i.e., the `central` config, as detailed in the link) and the other is in the user experiment directory. Users are supposed to only touch the user-level configuration file. The logic about which one takes priority is set in the `central` config for which the information can be found in the link. The user-level config file can be found at `/SNS/PG3/IPTS-xxxxx/shared/autoreduce/auto_params.json`. Once changes are made to the configuration file (either the `central` one or the user-level one), data can be processed in a batch, with the `all_pg3` utility, like `all_pg3 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`.\n\nWith the autoreduction routine, an `XML` file would also be saved, which can be later imported into the GUI for POWGEN data reduction inside `Mantid Workbench`. The `XML` file would be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`. To use it, log in the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and type `mantidworkbench`. Inside the interface, go to `Interfaces` in the menu, and further go to `Diffraction` => `Powder Diffraction Reduction` to launch the GUI for POWGEN data processing. There, we go to `File` => `Open`, and look for the saved `XML` file to load it into the GUI. Then we can make changes as needed and click on the `Reduce` button to process the data."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: POWGEN\nQ: I need to rerun POWGEN autoreduction.\nA: On POWGEN, the autoreduction routine is controlled through parameter files located at dedicated places. Instructions for populating those configuration files can be found here, `https://powder.ornl.gov/auto_reduce/powgen_auto.html`. There are two places where we can change the parameters. One is in the POWGEN shared folder (i.e., the `central` config, as detailed in the link) and the other is in the user experiment directory. Users are supposed to only touch the user-level configuration file. The logic about which one takes priority is set in the `central` config for which the information can be found in the link. The user-level config file can be found at `/SNS/PG3/IPTS-xxxxx/shared/autoreduce/auto_params.json`. Once changes are made to the configuration file (either the `central` one or the user-level one), data can be processed in a batch, with the `all_pg3` utility, like `all_pg3 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`.\n\nWith the autoreduction routine, an `XML` file would also be saved, which can be later imported into the GUI for POWGEN data reduction inside `Mantid Workbench`. The `XML` file would be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`. To use it, log in the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and type `mantidworkbench`. Inside the interface, go to `Interfaces` in the menu, and further go to `Diffraction` => `Powder Diffraction Reduction` to launch the GUI for POWGEN data processing. There, we go to `File` => `Open`, and look for the saved `XML` file to load it into the GUI. Then we can make changes as needed and click on the `Reduce` button to process the data."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: POWGEN\nQ: Reprocess POWGEN data for me.\nA: On POWGEN, the autoreduction routine is controlled through parameter files located at dedicated places. Instructions for populating those configuration files can be found here, `https://powder.ornl.gov/auto_reduce/powgen_auto.html`. There are two places where we can change the parameters. One is in the POWGEN shared folder (i.e., the `central` config, as detailed in the link) and the other is in the user experiment directory. Users are supposed to only touch the user-level configuration file. The logic about which one takes priority is set in the `central` config for which the information can be found in the link. The user-level config file can be found at `/SNS/PG3/IPTS-xxxxx/shared/autoreduce/auto_params.json`. Once changes are made to the configuration file (either the `central` one or the user-level one), data can be processed in a batch, with the `all_pg3` utility, like `all_pg3 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`.\n\nWith the autoreduction routine, an `XML` file would also be saved, which can be later imported into the GUI for POWGEN data reduction inside `Mantid Workbench`. The `XML` file would be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`. To use it, log in the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and type `mantidworkbench`. Inside the interface, go to `Interfaces` in the menu, and further go to `Diffraction` => `Powder Diffraction Reduction` to launch the GUI for POWGEN data processing. There, we go to `File` => `Open`, and look for the saved `XML` file to load it into the GUI. Then we can make changes as needed and click on the `Reduce` button to process the data."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: POWGEN\nQ: How can I rerun the processing on POWGEN?\nA: On POWGEN, the autoreduction routine is controlled through parameter files located at dedicated places. Instructions for populating those configuration files can be found here, `https://powder.ornl.gov/auto_reduce/powgen_auto.html`. There are two places where we can change the parameters. One is in the POWGEN shared folder (i.e., the `central` config, as detailed in the link) and the other is in the user experiment directory. Users are supposed to only touch the user-level configuration file. The logic about which one takes priority is set in the `central` config for which the information can be found in the link. The user-level config file can be found at `/SNS/PG3/IPTS-xxxxx/shared/autoreduce/auto_params.json`. Once changes are made to the configuration file (either the `central` one or the user-level one), data can be processed in a batch, with the `all_pg3` utility, like `all_pg3 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`.\n\nWith the autoreduction routine, an `XML` file would also be saved, which can be later imported into the GUI for POWGEN data reduction inside `Mantid Workbench`. The `XML` file would be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`. To use it, log in the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and type `mantidworkbench`. Inside the interface, go to `Interfaces` in the menu, and further go to `Diffraction` => `Powder Diffraction Reduction` to launch the GUI for POWGEN data processing. There, we go to `File` => `Open`, and look for the saved `XML` file to load it into the GUI. Then we can make changes as needed and click on the `Reduce` button to process the data."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: POWGEN\nQ: I want to rerun my POWGEN measurements.\nA: On POWGEN, the autoreduction routine is controlled through parameter files located at dedicated places. Instructions for populating those configuration files can be found here, `https://powder.ornl.gov/auto_reduce/powgen_auto.html`. There are two places where we can change the parameters. One is in the POWGEN shared folder (i.e., the `central` config, as detailed in the link) and the other is in the user experiment directory. Users are supposed to only touch the user-level configuration file. The logic about which one takes priority is set in the `central` config for which the information can be found in the link. The user-level config file can be found at `/SNS/PG3/IPTS-xxxxx/shared/autoreduce/auto_params.json`. Once changes are made to the configuration file (either the `central` one or the user-level one), data can be processed in a batch, with the `all_pg3` utility, like `all_pg3 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`.\n\nWith the autoreduction routine, an `XML` file would also be saved, which can be later imported into the GUI for POWGEN data reduction inside `Mantid Workbench`. The `XML` file would be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`. To use it, log in the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and type `mantidworkbench`. Inside the interface, go to `Interfaces` in the menu, and further go to `Diffraction` => `Powder Diffraction Reduction` to launch the GUI for POWGEN data processing. There, we go to `File` => `Open`, and look for the saved `XML` file to load it into the GUI. Then we can make changes as needed and click on the `Reduce` button to process the data."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: POWGEN\nQ: Tell me how to rerun POWGEN data reduction.\nA: On POWGEN, the autoreduction routine is controlled through parameter files located at dedicated places. Instructions for populating those configuration files can be found here, `https://powder.ornl.gov/auto_reduce/powgen_auto.html`. There are two places where we can change the parameters. One is in the POWGEN shared folder (i.e., the `central` config, as detailed in the link) and the other is in the user experiment directory. Users are supposed to only touch the user-level configuration file. The logic about which one takes priority is set in the `central` config for which the information can be found in the link. The user-level config file can be found at `/SNS/PG3/IPTS-xxxxx/shared/autoreduce/auto_params.json`. Once changes are made to the configuration file (either the `central` one or the user-level one), data can be processed in a batch, with the `all_pg3` utility, like `all_pg3 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`.\n\nWith the autoreduction routine, an `XML` file would also be saved, which can be later imported into the GUI for POWGEN data reduction inside `Mantid Workbench`. The `XML` file would be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`. To use it, log in the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and type `mantidworkbench`. Inside the interface, go to `Interfaces` in the menu, and further go to `Diffraction` => `Powder Diffraction Reduction` to launch the GUI for POWGEN data processing. There, we go to `File` => `Open`, and look for the saved `XML` file to load it into the GUI. Then we can make changes as needed and click on the `Reduce` button to process the data."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: POWGEN\nQ: I need help rerunning POWGEN processing.\nA: On POWGEN, the autoreduction routine is controlled through parameter files located at dedicated places. Instructions for populating those configuration files can be found here, `https://powder.ornl.gov/auto_reduce/powgen_auto.html`. There are two places where we can change the parameters. One is in the POWGEN shared folder (i.e., the `central` config, as detailed in the link) and the other is in the user experiment directory. Users are supposed to only touch the user-level configuration file. The logic about which one takes priority is set in the `central` config for which the information can be found in the link. The user-level config file can be found at `/SNS/PG3/IPTS-xxxxx/shared/autoreduce/auto_params.json`. Once changes are made to the configuration file (either the `central` one or the user-level one), data can be processed in a batch, with the `all_pg3` utility, like `all_pg3 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`.\n\nWith the autoreduction routine, an `XML` file would also be saved, which can be later imported into the GUI for POWGEN data reduction inside `Mantid Workbench`. The `XML` file would be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`. To use it, log in the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and type `mantidworkbench`. Inside the interface, go to `Interfaces` in the menu, and further go to `Diffraction` => `Powder Diffraction Reduction` to launch the GUI for POWGEN data processing. There, we go to `File` => `Open`, and look for the saved `XML` file to load it into the GUI. Then we can make changes as needed and click on the `Reduce` button to process the data."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: POWGEN\nQ: Rerun POWGEN data processing steps.\nA: On POWGEN, the autoreduction routine is controlled through parameter files located at dedicated places. Instructions for populating those configuration files can be found here, `https://powder.ornl.gov/auto_reduce/powgen_auto.html`. There are two places where we can change the parameters. One is in the POWGEN shared folder (i.e., the `central` config, as detailed in the link) and the other is in the user experiment directory. Users are supposed to only touch the user-level configuration file. The logic about which one takes priority is set in the `central` config for which the information can be found in the link. The user-level config file can be found at `/SNS/PG3/IPTS-xxxxx/shared/autoreduce/auto_params.json`. Once changes are made to the configuration file (either the `central` one or the user-level one), data can be processed in a batch, with the `all_pg3` utility, like `all_pg3 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`.\n\nWith the autoreduction routine, an `XML` file would also be saved, which can be later imported into the GUI for POWGEN data reduction inside `Mantid Workbench`. The `XML` file would be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`. To use it, log in the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and type `mantidworkbench`. Inside the interface, go to `Interfaces` in the menu, and further go to `Diffraction` => `Powder Diffraction Reduction` to launch the GUI for POWGEN data processing. There, we go to `File` => `Open`, and look for the saved `XML` file to load it into the GUI. Then we can make changes as needed and click on the `Reduce` button to process the data."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: POWGEN\nQ: Guide me through rerunning POWGEN autoreduction.\nA: On POWGEN, the autoreduction routine is controlled through parameter files located at dedicated places. Instructions for populating those configuration files can be found here, `https://powder.ornl.gov/auto_reduce/powgen_auto.html`. There are two places where we can change the parameters. One is in the POWGEN shared folder (i.e., the `central` config, as detailed in the link) and the other is in the user experiment directory. Users are supposed to only touch the user-level configuration file. The logic about which one takes priority is set in the `central` config for which the information can be found in the link. The user-level config file can be found at `/SNS/PG3/IPTS-xxxxx/shared/autoreduce/auto_params.json`. Once changes are made to the configuration file (either the `central` one or the user-level one), data can be processed in a batch, with the `all_pg3` utility, like `all_pg3 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`.\n\nWith the autoreduction routine, an `XML` file would also be saved, which can be later imported into the GUI for POWGEN data reduction inside `Mantid Workbench`. The `XML` file would be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`. To use it, log in the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and type `mantidworkbench`. Inside the interface, go to `Interfaces` in the menu, and further go to `Diffraction` => `Powder Diffraction Reduction` to launch the GUI for POWGEN data processing. There, we go to `File` => `Open`, and look for the saved `XML` file to load it into the GUI. Then we can make changes as needed and click on the `Reduce` button to process the data."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: POWGEN\nQ: How to reprocess POWGEN measurements?\nA: On POWGEN, the autoreduction routine is controlled through parameter files located at dedicated places. Instructions for populating those configuration files can be found here, `https://powder.ornl.gov/auto_reduce/powgen_auto.html`. There are two places where we can change the parameters. One is in the POWGEN shared folder (i.e., the `central` config, as detailed in the link) and the other is in the user experiment directory. Users are supposed to only touch the user-level configuration file. The logic about which one takes priority is set in the `central` config for which the information can be found in the link. The user-level config file can be found at `/SNS/PG3/IPTS-xxxxx/shared/autoreduce/auto_params.json`. Once changes are made to the configuration file (either the `central` one or the user-level one), data can be processed in a batch, with the `all_pg3` utility, like `all_pg3 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`.\n\nWith the autoreduction routine, an `XML` file would also be saved, which can be later imported into the GUI for POWGEN data reduction inside `Mantid Workbench`. The `XML` file would be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`. To use it, log in the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and type `mantidworkbench`. Inside the interface, go to `Interfaces` in the menu, and further go to `Diffraction` => `Powder Diffraction Reduction` to launch the GUI for POWGEN data processing. There, we go to `File` => `Open`, and look for the saved `XML` file to load it into the GUI. Then we can make changes as needed and click on the `Reduce` button to process the data."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: POWGEN\nQ: I want to redo POWGEN data processing.\nA: On POWGEN, the autoreduction routine is controlled through parameter files located at dedicated places. Instructions for populating those configuration files can be found here, `https://powder.ornl.gov/auto_reduce/powgen_auto.html`. There are two places where we can change the parameters. One is in the POWGEN shared folder (i.e., the `central` config, as detailed in the link) and the other is in the user experiment directory. Users are supposed to only touch the user-level configuration file. The logic about which one takes priority is set in the `central` config for which the information can be found in the link. The user-level config file can be found at `/SNS/PG3/IPTS-xxxxx/shared/autoreduce/auto_params.json`. Once changes are made to the configuration file (either the `central` one or the user-level one), data can be processed in a batch, with the `all_pg3` utility, like `all_pg3 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`.\n\nWith the autoreduction routine, an `XML` file would also be saved, which can be later imported into the GUI for POWGEN data reduction inside `Mantid Workbench`. The `XML` file would be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`. To use it, log in the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and type `mantidworkbench`. Inside the interface, go to `Interfaces` in the menu, and further go to `Diffraction` => `Powder Diffraction Reduction` to launch the GUI for POWGEN data processing. There, we go to `File` => `Open`, and look for the saved `XML` file to load it into the GUI. Then we can make changes as needed and click on the `Reduce` button to process the data."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: POWGEN\nQ: Rerun my POWGEN data analysis.\nA: On POWGEN, the autoreduction routine is controlled through parameter files located at dedicated places. Instructions for populating those configuration files can be found here, `https://powder.ornl.gov/auto_reduce/powgen_auto.html`. There are two places where we can change the parameters. One is in the POWGEN shared folder (i.e., the `central` config, as detailed in the link) and the other is in the user experiment directory. Users are supposed to only touch the user-level configuration file. The logic about which one takes priority is set in the `central` config for which the information can be found in the link. The user-level config file can be found at `/SNS/PG3/IPTS-xxxxx/shared/autoreduce/auto_params.json`. Once changes are made to the configuration file (either the `central` one or the user-level one), data can be processed in a batch, with the `all_pg3` utility, like `all_pg3 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`.\n\nWith the autoreduction routine, an `XML` file would also be saved, which can be later imported into the GUI for POWGEN data reduction inside `Mantid Workbench`. The `XML` file would be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`. To use it, log in the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and type `mantidworkbench`. Inside the interface, go to `Interfaces` in the menu, and further go to `Diffraction` => `Powder Diffraction Reduction` to launch the GUI for POWGEN data processing. There, we go to `File` => `Open`, and look for the saved `XML` file to load it into the GUI. Then we can make changes as needed and click on the `Reduce` button to process the data."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: POWGEN\nQ: Show me how to rerun POWGEN processing.\nA: On POWGEN, the autoreduction routine is controlled through parameter files located at dedicated places. Instructions for populating those configuration files can be found here, `https://powder.ornl.gov/auto_reduce/powgen_auto.html`. There are two places where we can change the parameters. One is in the POWGEN shared folder (i.e., the `central` config, as detailed in the link) and the other is in the user experiment directory. Users are supposed to only touch the user-level configuration file. The logic about which one takes priority is set in the `central` config for which the information can be found in the link. The user-level config file can be found at `/SNS/PG3/IPTS-xxxxx/shared/autoreduce/auto_params.json`. Once changes are made to the configuration file (either the `central` one or the user-level one), data can be processed in a batch, with the `all_pg3` utility, like `all_pg3 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`.\n\nWith the autoreduction routine, an `XML` file would also be saved, which can be later imported into the GUI for POWGEN data reduction inside `Mantid Workbench`. The `XML` file would be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`. To use it, log in the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and type `mantidworkbench`. Inside the interface, go to `Interfaces` in the menu, and further go to `Diffraction` => `Powder Diffraction Reduction` to launch the GUI for POWGEN data processing. There, we go to `File` => `Open`, and look for the saved `XML` file to load it into the GUI. Then we can make changes as needed and click on the `Reduce` button to process the data."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: POWGEN\nQ: I need to process my POWGEN data. Give me some information.\nA: Normally, the POWGEN autoreduction routine will take care of the data processing and reduced data can be found at `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. On POWGEN, the autoreduction routine is controlled through parameter files located at dedicated places. Instructions for populating those configuration files can be found here, `https://powder.ornl.gov/auto_reduce/powgen_auto.html`. There are two places where we can change the parameters. One is in the POWGEN shared folder (i.e., the `central` config, as detailed in the link) and the other is in the user experiment directory. Users are supposed to only touch the user-level configuration file. The logic about which one takes priority is set in the `central` config for which the information can be found in the link. The user-level config file can be found at `/SNS/PG3/IPTS-xxxxx/shared/autoreduce/auto_params.json`. Once changes are made to the configuration file (either the `central` one or the user-level one), data can be processed in a batch, with the `all_pg3` utility, like `all_pg3 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`.\n\nWith the autoreduction routine, an `XML` file would also be saved, which can be later imported into the GUI for POWGEN data reduction inside `Mantid Workbench`. The `XML` file would be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`. To use it, log in the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and type `mantidworkbench`. Inside the interface, go to `Interfaces` in the menu, and further go to `Diffraction` => `Powder Diffraction Reduction` to launch the GUI for POWGEN data processing. There, we go to `File` => `Open`, and look for the saved `XML` file to load it into the GUI. Then we can make changes as needed and click on the `Reduce` button to process the data."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: POWGEN\nQ: How do I process POWGEN data?\nA: Normally, the POWGEN autoreduction routine will take care of the data processing and reduced data can be found at `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. On POWGEN, the autoreduction routine is controlled through parameter files located at dedicated places. Instructions for populating those configuration files can be found here, `https://powder.ornl.gov/auto_reduce/powgen_auto.html`. There are two places where we can change the parameters. One is in the POWGEN shared folder (i.e., the `central` config, as detailed in the link) and the other is in the user experiment directory. Users are supposed to only touch the user-level configuration file. The logic about which one takes priority is set in the `central` config for which the information can be found in the link. The user-level config file can be found at `/SNS/PG3/IPTS-xxxxx/shared/autoreduce/auto_params.json`. Once changes are made to the configuration file (either the `central` one or the user-level one), data can be processed in a batch, with the `all_pg3` utility, like `all_pg3 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`.\n\nWith the autoreduction routine, an `XML` file would also be saved, which can be later imported into the GUI for POWGEN data reduction inside `Mantid Workbench`. The `XML` file would be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`. To use it, log in the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and type `mantidworkbench`. Inside the interface, go to `Interfaces` in the menu, and further go to `Diffraction` => `Powder Diffraction Reduction` to launch the GUI for POWGEN data processing. There, we go to `File` => `Open`, and look for the saved `XML` file to load it into the GUI. Then we can make changes as needed and click on the `Reduce` button to process the data."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: POWGEN\nQ: I want to process my POWGEN measurements.\nA: Normally, the POWGEN autoreduction routine will take care of the data processing and reduced data can be found at `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. On POWGEN, the autoreduction routine is controlled through parameter files located at dedicated places. Instructions for populating those configuration files can be found here, `https://powder.ornl.gov/auto_reduce/powgen_auto.html`. There are two places where we can change the parameters. One is in the POWGEN shared folder (i.e., the `central` config, as detailed in the link) and the other is in the user experiment directory. Users are supposed to only touch the user-level configuration file. The logic about which one takes priority is set in the `central` config for which the information can be found in the link. The user-level config file can be found at `/SNS/PG3/IPTS-xxxxx/shared/autoreduce/auto_params.json`. Once changes are made to the configuration file (either the `central` one or the user-level one), data can be processed in a batch, with the `all_pg3` utility, like `all_pg3 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`.\n\nWith the autoreduction routine, an `XML` file would also be saved, which can be later imported into the GUI for POWGEN data reduction inside `Mantid Workbench`. The `XML` file would be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`. To use it, log in the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and type `mantidworkbench`. Inside the interface, go to `Interfaces` in the menu, and further go to `Diffraction` => `Powder Diffraction Reduction` to launch the GUI for POWGEN data processing. There, we go to `File` => `Open`, and look for the saved `XML` file to load it into the GUI. Then we can make changes as needed and click on the `Reduce` button to process the data."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: POWGEN\nQ: Tell me about POWGEN data processing.\nA: Normally, the POWGEN autoreduction routine will take care of the data processing and reduced data can be found at `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. On POWGEN, the autoreduction routine is controlled through parameter files located at dedicated places. Instructions for populating those configuration files can be found here, `https://powder.ornl.gov/auto_reduce/powgen_auto.html`. There are two places where we can change the parameters. One is in the POWGEN shared folder (i.e., the `central` config, as detailed in the link) and the other is in the user experiment directory. Users are supposed to only touch the user-level configuration file. The logic about which one takes priority is set in the `central` config for which the information can be found in the link. The user-level config file can be found at `/SNS/PG3/IPTS-xxxxx/shared/autoreduce/auto_params.json`. Once changes are made to the configuration file (either the `central` one or the user-level one), data can be processed in a batch, with the `all_pg3` utility, like `all_pg3 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`.\n\nWith the autoreduction routine, an `XML` file would also be saved, which can be later imported into the GUI for POWGEN data reduction inside `Mantid Workbench`. The `XML` file would be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`. To use it, log in the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and type `mantidworkbench`. Inside the interface, go to `Interfaces` in the menu, and further go to `Diffraction` => `Powder Diffraction Reduction` to launch the GUI for POWGEN data processing. There, we go to `File` => `Open`, and look for the saved `XML` file to load it into the GUI. Then we can make changes as needed and click on the `Reduce` button to process the data."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: POWGEN\nQ: How can I process data from POWGEN?\nA: Normally, the POWGEN autoreduction routine will take care of the data processing and reduced data can be found at `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. On POWGEN, the autoreduction routine is controlled through parameter files located at dedicated places. Instructions for populating those configuration files can be found here, `https://powder.ornl.gov/auto_reduce/powgen_auto.html`. There are two places where we can change the parameters. One is in the POWGEN shared folder (i.e., the `central` config, as detailed in the link) and the other is in the user experiment directory. Users are supposed to only touch the user-level configuration file. The logic about which one takes priority is set in the `central` config for which the information can be found in the link. The user-level config file can be found at `/SNS/PG3/IPTS-xxxxx/shared/autoreduce/auto_params.json`. Once changes are made to the configuration file (either the `central` one or the user-level one), data can be processed in a batch, with the `all_pg3` utility, like `all_pg3 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`.\n\nWith the autoreduction routine, an `XML` file would also be saved, which can be later imported into the GUI for POWGEN data reduction inside `Mantid Workbench`. The `XML` file would be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`. To use it, log in the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and type `mantidworkbench`. Inside the interface, go to `Interfaces` in the menu, and further go to `Diffraction` => `Powder Diffraction Reduction` to launch the GUI for POWGEN data processing. There, we go to `File` => `Open`, and look for the saved `XML` file to load it into the GUI. Then we can make changes as needed and click on the `Reduce` button to process the data."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: POWGEN\nQ: I need help with POWGEN data reduction.\nA: Normally, the POWGEN autoreduction routine will take care of the data processing and reduced data can be found at `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. On POWGEN, the autoreduction routine is controlled through parameter files located at dedicated places. Instructions for populating those configuration files can be found here, `https://powder.ornl.gov/auto_reduce/powgen_auto.html`. There are two places where we can change the parameters. One is in the POWGEN shared folder (i.e., the `central` config, as detailed in the link) and the other is in the user experiment directory. Users are supposed to only touch the user-level configuration file. The logic about which one takes priority is set in the `central` config for which the information can be found in the link. The user-level config file can be found at `/SNS/PG3/IPTS-xxxxx/shared/autoreduce/auto_params.json`. Once changes are made to the configuration file (either the `central` one or the user-level one), data can be processed in a batch, with the `all_pg3` utility, like `all_pg3 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`.\n\nWith the autoreduction routine, an `XML` file would also be saved, which can be later imported into the GUI for POWGEN data reduction inside `Mantid Workbench`. The `XML` file would be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`. To use it, log in the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and type `mantidworkbench`. Inside the interface, go to `Interfaces` in the menu, and further go to `Diffraction` => `Powder Diffraction Reduction` to launch the GUI for POWGEN data processing. There, we go to `File` => `Open`, and look for the saved `XML` file to load it into the GUI. Then we can make changes as needed and click on the `Reduce` button to process the data."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: POWGEN\nQ: Process my POWGEN data.\nA: Normally, the POWGEN autoreduction routine will take care of the data processing and reduced data can be found at `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. On POWGEN, the autoreduction routine is controlled through parameter files located at dedicated places. Instructions for populating those configuration files can be found here, `https://powder.ornl.gov/auto_reduce/powgen_auto.html`. There are two places where we can change the parameters. One is in the POWGEN shared folder (i.e., the `central` config, as detailed in the link) and the other is in the user experiment directory. Users are supposed to only touch the user-level configuration file. The logic about which one takes priority is set in the `central` config for which the information can be found in the link. The user-level config file can be found at `/SNS/PG3/IPTS-xxxxx/shared/autoreduce/auto_params.json`. Once changes are made to the configuration file (either the `central` one or the user-level one), data can be processed in a batch, with the `all_pg3` utility, like `all_pg3 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`.\n\nWith the autoreduction routine, an `XML` file would also be saved, which can be later imported into the GUI for POWGEN data reduction inside `Mantid Workbench`. The `XML` file would be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`. To use it, log in the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and type `mantidworkbench`. Inside the interface, go to `Interfaces` in the menu, and further go to `Diffraction` => `Powder Diffraction Reduction` to launch the GUI for POWGEN data processing. There, we go to `File` => `Open`, and look for the saved `XML` file to load it into the GUI. Then we can make changes as needed and click on the `Reduce` button to process the data."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: POWGEN\nQ: What's the procedure for POWGEN data processing?\nA: Normally, the POWGEN autoreduction routine will take care of the data processing and reduced data can be found at `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. On POWGEN, the autoreduction routine is controlled through parameter files located at dedicated places. Instructions for populating those configuration files can be found here, `https://powder.ornl.gov/auto_reduce/powgen_auto.html`. There are two places where we can change the parameters. One is in the POWGEN shared folder (i.e., the `central` config, as detailed in the link) and the other is in the user experiment directory. Users are supposed to only touch the user-level configuration file. The logic about which one takes priority is set in the `central` config for which the information can be found in the link. The user-level config file can be found at `/SNS/PG3/IPTS-xxxxx/shared/autoreduce/auto_params.json`. Once changes are made to the configuration file (either the `central` one or the user-level one), data can be processed in a batch, with the `all_pg3` utility, like `all_pg3 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`.\n\nWith the autoreduction routine, an `XML` file would also be saved, which can be later imported into the GUI for POWGEN data reduction inside `Mantid Workbench`. The `XML` file would be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`. To use it, log in the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and type `mantidworkbench`. Inside the interface, go to `Interfaces` in the menu, and further go to `Diffraction` => `Powder Diffraction Reduction` to launch the GUI for POWGEN data processing. There, we go to `File` => `Open`, and look for the saved `XML` file to load it into the GUI. Then we can make changes as needed and click on the `Reduce` button to process the data."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: POWGEN\nQ: I want to reduce POWGEN data.\nA: Normally, the POWGEN autoreduction routine will take care of the data processing and reduced data can be found at `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. On POWGEN, the autoreduction routine is controlled through parameter files located at dedicated places. Instructions for populating those configuration files can be found here, `https://powder.ornl.gov/auto_reduce/powgen_auto.html`. There are two places where we can change the parameters. One is in the POWGEN shared folder (i.e., the `central` config, as detailed in the link) and the other is in the user experiment directory. Users are supposed to only touch the user-level configuration file. The logic about which one takes priority is set in the `central` config for which the information can be found in the link. The user-level config file can be found at `/SNS/PG3/IPTS-xxxxx/shared/autoreduce/auto_params.json`. Once changes are made to the configuration file (either the `central` one or the user-level one), data can be processed in a batch, with the `all_pg3` utility, like `all_pg3 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`.\n\nWith the autoreduction routine, an `XML` file would also be saved, which can be later imported into the GUI for POWGEN data reduction inside `Mantid Workbench`. The `XML` file would be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`. To use it, log in the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and type `mantidworkbench`. Inside the interface, go to `Interfaces` in the menu, and further go to `Diffraction` => `Powder Diffraction Reduction` to launch the GUI for POWGEN data processing. There, we go to `File` => `Open`, and look for the saved `XML` file to load it into the GUI. Then we can make changes as needed and click on the `Reduce` button to process the data."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: POWGEN\nQ: Guide me through POWGEN data processing.\nA: Normally, the POWGEN autoreduction routine will take care of the data processing and reduced data can be found at `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. On POWGEN, the autoreduction routine is controlled through parameter files located at dedicated places. Instructions for populating those configuration files can be found here, `https://powder.ornl.gov/auto_reduce/powgen_auto.html`. There are two places where we can change the parameters. One is in the POWGEN shared folder (i.e., the `central` config, as detailed in the link) and the other is in the user experiment directory. Users are supposed to only touch the user-level configuration file. The logic about which one takes priority is set in the `central` config for which the information can be found in the link. The user-level config file can be found at `/SNS/PG3/IPTS-xxxxx/shared/autoreduce/auto_params.json`. Once changes are made to the configuration file (either the `central` one or the user-level one), data can be processed in a batch, with the `all_pg3` utility, like `all_pg3 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`.\n\nWith the autoreduction routine, an `XML` file would also be saved, which can be later imported into the GUI for POWGEN data reduction inside `Mantid Workbench`. The `XML` file would be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`. To use it, log in the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and type `mantidworkbench`. Inside the interface, go to `Interfaces` in the menu, and further go to `Diffraction` => `Powder Diffraction Reduction` to launch the GUI for POWGEN data processing. There, we go to `File` => `Open`, and look for the saved `XML` file to load it into the GUI. Then we can make changes as needed and click on the `Reduce` button to process the data."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: POWGEN\nQ: How to handle POWGEN data reduction?\nA: Normally, the POWGEN autoreduction routine will take care of the data processing and reduced data can be found at `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. On POWGEN, the autoreduction routine is controlled through parameter files located at dedicated places. Instructions for populating those configuration files can be found here, `https://powder.ornl.gov/auto_reduce/powgen_auto.html`. There are two places where we can change the parameters. One is in the POWGEN shared folder (i.e., the `central` config, as detailed in the link) and the other is in the user experiment directory. Users are supposed to only touch the user-level configuration file. The logic about which one takes priority is set in the `central` config for which the information can be found in the link. The user-level config file can be found at `/SNS/PG3/IPTS-xxxxx/shared/autoreduce/auto_params.json`. Once changes are made to the configuration file (either the `central` one or the user-level one), data can be processed in a batch, with the `all_pg3` utility, like `all_pg3 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`.\n\nWith the autoreduction routine, an `XML` file would also be saved, which can be later imported into the GUI for POWGEN data reduction inside `Mantid Workbench`. The `XML` file would be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`. To use it, log in the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and type `mantidworkbench`. Inside the interface, go to `Interfaces` in the menu, and further go to `Diffraction` => `Powder Diffraction Reduction` to launch the GUI for POWGEN data processing. There, we go to `File` => `Open`, and look for the saved `XML` file to load it into the GUI. Then we can make changes as needed and click on the `Reduce` button to process the data."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: POWGEN\nQ: I need information on POWGEN data processing.\nA: Normally, the POWGEN autoreduction routine will take care of the data processing and reduced data can be found at `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. On POWGEN, the autoreduction routine is controlled through parameter files located at dedicated places. Instructions for populating those configuration files can be found here, `https://powder.ornl.gov/auto_reduce/powgen_auto.html`. There are two places where we can change the parameters. One is in the POWGEN shared folder (i.e., the `central` config, as detailed in the link) and the other is in the user experiment directory. Users are supposed to only touch the user-level configuration file. The logic about which one takes priority is set in the `central` config for which the information can be found in the link. The user-level config file can be found at `/SNS/PG3/IPTS-xxxxx/shared/autoreduce/auto_params.json`. Once changes are made to the configuration file (either the `central` one or the user-level one), data can be processed in a batch, with the `all_pg3` utility, like `all_pg3 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`.\n\nWith the autoreduction routine, an `XML` file would also be saved, which can be later imported into the GUI for POWGEN data reduction inside `Mantid Workbench`. The `XML` file would be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`. To use it, log in the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and type `mantidworkbench`. Inside the interface, go to `Interfaces` in the menu, and further go to `Diffraction` => `Powder Diffraction Reduction` to launch the GUI for POWGEN data processing. There, we go to `File` => `Open`, and look for the saved `XML` file to load it into the GUI. Then we can make changes as needed and click on the `Reduce` button to process the data."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: POWGEN\nQ: Explain POWGEN data processing steps.\nA: Normally, the POWGEN autoreduction routine will take care of the data processing and reduced data can be found at `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. On POWGEN, the autoreduction routine is controlled through parameter files located at dedicated places. Instructions for populating those configuration files can be found here, `https://powder.ornl.gov/auto_reduce/powgen_auto.html`. There are two places where we can change the parameters. One is in the POWGEN shared folder (i.e., the `central` config, as detailed in the link) and the other is in the user experiment directory. Users are supposed to only touch the user-level configuration file. The logic about which one takes priority is set in the `central` config for which the information can be found in the link. The user-level config file can be found at `/SNS/PG3/IPTS-xxxxx/shared/autoreduce/auto_params.json`. Once changes are made to the configuration file (either the `central` one or the user-level one), data can be processed in a batch, with the `all_pg3` utility, like `all_pg3 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`.\n\nWith the autoreduction routine, an `XML` file would also be saved, which can be later imported into the GUI for POWGEN data reduction inside `Mantid Workbench`. The `XML` file would be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`. To use it, log in the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and type `mantidworkbench`. Inside the interface, go to `Interfaces` in the menu, and further go to `Diffraction` => `Powder Diffraction Reduction` to launch the GUI for POWGEN data processing. There, we go to `File` => `Open`, and look for the saved `XML` file to load it into the GUI. Then we can make changes as needed and click on the `Reduce` button to process the data."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: POWGEN\nQ: How do I reduce my POWGEN data?\nA: Normally, the POWGEN autoreduction routine will take care of the data processing and reduced data can be found at `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. On POWGEN, the autoreduction routine is controlled through parameter files located at dedicated places. Instructions for populating those configuration files can be found here, `https://powder.ornl.gov/auto_reduce/powgen_auto.html`. There are two places where we can change the parameters. One is in the POWGEN shared folder (i.e., the `central` config, as detailed in the link) and the other is in the user experiment directory. Users are supposed to only touch the user-level configuration file. The logic about which one takes priority is set in the `central` config for which the information can be found in the link. The user-level config file can be found at `/SNS/PG3/IPTS-xxxxx/shared/autoreduce/auto_params.json`. Once changes are made to the configuration file (either the `central` one or the user-level one), data can be processed in a batch, with the `all_pg3` utility, like `all_pg3 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`.\n\nWith the autoreduction routine, an `XML` file would also be saved, which can be later imported into the GUI for POWGEN data reduction inside `Mantid Workbench`. The `XML` file would be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`. To use it, log in the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and type `mantidworkbench`. Inside the interface, go to `Interfaces` in the menu, and further go to `Diffraction` => `Powder Diffraction Reduction` to launch the GUI for POWGEN data processing. There, we go to `File` => `Open`, and look for the saved `XML` file to load it into the GUI. Then we can make changes as needed and click on the `Reduce` button to process the data."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: POWGEN\nQ: Tell me about processing data on POWGEN.\nA: Normally, the POWGEN autoreduction routine will take care of the data processing and reduced data can be found at `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. On POWGEN, the autoreduction routine is controlled through parameter files located at dedicated places. Instructions for populating those configuration files can be found here, `https://powder.ornl.gov/auto_reduce/powgen_auto.html`. There are two places where we can change the parameters. One is in the POWGEN shared folder (i.e., the `central` config, as detailed in the link) and the other is in the user experiment directory. Users are supposed to only touch the user-level configuration file. The logic about which one takes priority is set in the `central` config for which the information can be found in the link. The user-level config file can be found at `/SNS/PG3/IPTS-xxxxx/shared/autoreduce/auto_params.json`. Once changes are made to the configuration file (either the `central` one or the user-level one), data can be processed in a batch, with the `all_pg3` utility, like `all_pg3 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`.\n\nWith the autoreduction routine, an `XML` file would also be saved, which can be later imported into the GUI for POWGEN data reduction inside `Mantid Workbench`. The `XML` file would be saved into `/SNS/PG3/IPTS-xxxxx/shared/autoreduce`. To use it, log in the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and type `mantidworkbench`. Inside the interface, go to `Interfaces` in the menu, and further go to `Diffraction` => `Powder Diffraction Reduction` to launch the GUI for POWGEN data processing. There, we go to `File` => `Open`, and look for the saved `XML` file to load it into the GUI. Then we can make changes as needed and click on the `Reduce` button to process the data."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: NOMAD\nQ: I need to rerun the processing for my NOMAD data. Give me some information.\nA: On NOMAD, there are two levels of parameter configuration for the autoreduction. In the NOMAD shared directory, there is a configuration file in the JSON format (`/SNS/NOM/shared/autoreduce/auto_config.json`) containing some common parameters shared across all measurements. Only NOMAD team members have the permission of editing and in fact, parameters included in the file are not expected to be changed frequently. Characterization runs information (typically, calibration file, container and empty instrument background, and vanadium normalization) is contained in `/SNS/NOM/shared/autoreduce/auto_exp.csv`. In case any of the two files are updated and we need to rerun the autoreduction, we can log into the ORNL Analysis (see here, analysis.sns.gov) and run the command like `all_nom 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. More detailed information can be found here, `https://powder.ornl.gov/auto_reduce/nomad_auto.html`.\n\nThe other level of configuration is measurement-specific, in which case individual measurements have to be processed individually based on the input JSON files created through the autoreduction routine. Those input files can be found in locations like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/multi_banks_summed/Input` or `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` on the ORNL Analysis cluster. The `multi_banks` mode here means the data would be grouped according to those physical banks of detectors. The `single_bank` mode means data from all detectors would be merged into a single pattern. The `summed` here in the path means all files corresponding to the same measurement are summed together. This is specific to the convention followed on NOMAD for the data collection -- usually, a long data collection would be done through multiple chunks of collection. For example, a total 8 C proton charge accumulation would be collected through 4 chunks, with each chunk contributing 2 C proton charge accumulation. Depending on which mode we want to go with (i.e., `multi_banks` or `single_bank`), we can go into the corresponding directory, make changes to the intended input file and run the data processing via `mts <input>.json` from a terminal (for sure, you need to run something like `cd /SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` to go to the directory first, in the terminal). `<input>.json` (without bracket) represents the input JSON file that you want to run. Usually, parameters like `Scale` in the `Background` entry of `Sample` or the `Type` entry in `AbsorptionCorrection` may be expected to be changed for the re-processing. Detailed information about the input file for running `MantidTotalScattering` (what the command `mts` is short for) can be found here, `https://powder.ornl.gov/total_scattering/data_reduction/mts_doc.html`.\n\nFor autoreduction and the processing with `all_nom`, output of reduced data can be found at something like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. For manual processing with `mts`, the output directory can be specified explicitly in the input JSON file."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: NOMAD\nQ: I want to reprocess my NOMAD data.\nA: On NOMAD, there are two levels of parameter configuration for the autoreduction. In the NOMAD shared directory, there is a configuration file in the JSON format (`/SNS/NOM/shared/autoreduce/auto_config.json`) containing some common parameters shared across all measurements. Only NOMAD team members have the permission of editing and in fact, parameters included in the file are not expected to be changed frequently. Characterization runs information (typically, calibration file, container and empty instrument background, and vanadium normalization) is contained in `/SNS/NOM/shared/autoreduce/auto_exp.csv`. In case any of the two files are updated and we need to rerun the autoreduction, we can log into the ORNL Analysis (see here, analysis.sns.gov) and run the command like `all_nom 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. More detailed information can be found here, `https://powder.ornl.gov/auto_reduce/nomad_auto.html`.\n\nThe other level of configuration is measurement-specific, in which case individual measurements have to be processed individually based on the input JSON files created through the autoreduction routine. Those input files can be found in locations like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/multi_banks_summed/Input` or `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` on the ORNL Analysis cluster. The `multi_banks` mode here means the data would be grouped according to those physical banks of detectors. The `single_bank` mode means data from all detectors would be merged into a single pattern. The `summed` here in the path means all files corresponding to the same measurement are summed together. This is specific to the convention followed on NOMAD for the data collection -- usually, a long data collection would be done through multiple chunks of collection. For example, a total 8 C proton charge accumulation would be collected through 4 chunks, with each chunk contributing 2 C proton charge accumulation. Depending on which mode we want to go with (i.e., `multi_banks` or `single_bank`), we can go into the corresponding directory, make changes to the intended input file and run the data processing via `mts <input>.json` from a terminal (for sure, you need to run something like `cd /SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` to go to the directory first, in the terminal). `<input>.json` (without bracket) represents the input JSON file that you want to run. Usually, parameters like `Scale` in the `Background` entry of `Sample` or the `Type` entry in `AbsorptionCorrection` may be expected to be changed for the re-processing. Detailed information about the input file for running `MantidTotalScattering` (what the command `mts` is short for) can be found here, `https://powder.ornl.gov/total_scattering/data_reduction/mts_doc.html`.\n\nFor autoreduction and the processing with `all_nom`, output of reduced data can be found at something like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. For manual processing with `mts`, the output directory can be specified explicitly in the input JSON file."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: NOMAD\nQ: How do I rerun NOMAD data processing?\nA: On NOMAD, there are two levels of parameter configuration for the autoreduction. In the NOMAD shared directory, there is a configuration file in the JSON format (`/SNS/NOM/shared/autoreduce/auto_config.json`) containing some common parameters shared across all measurements. Only NOMAD team members have the permission of editing and in fact, parameters included in the file are not expected to be changed frequently. Characterization runs information (typically, calibration file, container and empty instrument background, and vanadium normalization) is contained in `/SNS/NOM/shared/autoreduce/auto_exp.csv`. In case any of the two files are updated and we need to rerun the autoreduction, we can log into the ORNL Analysis (see here, analysis.sns.gov) and run the command like `all_nom 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. More detailed information can be found here, `https://powder.ornl.gov/auto_reduce/nomad_auto.html`.\n\nThe other level of configuration is measurement-specific, in which case individual measurements have to be processed individually based on the input JSON files created through the autoreduction routine. Those input files can be found in locations like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/multi_banks_summed/Input` or `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` on the ORNL Analysis cluster. The `multi_banks` mode here means the data would be grouped according to those physical banks of detectors. The `single_bank` mode means data from all detectors would be merged into a single pattern. The `summed` here in the path means all files corresponding to the same measurement are summed together. This is specific to the convention followed on NOMAD for the data collection -- usually, a long data collection would be done through multiple chunks of collection. For example, a total 8 C proton charge accumulation would be collected through 4 chunks, with each chunk contributing 2 C proton charge accumulation. Depending on which mode we want to go with (i.e., `multi_banks` or `single_bank`), we can go into the corresponding directory, make changes to the intended input file and run the data processing via `mts <input>.json` from a terminal (for sure, you need to run something like `cd /SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` to go to the directory first, in the terminal). `<input>.json` (without bracket) represents the input JSON file that you want to run. Usually, parameters like `Scale` in the `Background` entry of `Sample` or the `Type` entry in `AbsorptionCorrection` may be expected to be changed for the re-processing. Detailed information about the input file for running `MantidTotalScattering` (what the command `mts` is short for) can be found here, `https://powder.ornl.gov/total_scattering/data_reduction/mts_doc.html`.\n\nFor autoreduction and the processing with `all_nom`, output of reduced data can be found at something like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. For manual processing with `mts`, the output directory can be specified explicitly in the input JSON file."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: NOMAD\nQ: I need to rerun NOMAD autoreduction.\nA: On NOMAD, there are two levels of parameter configuration for the autoreduction. In the NOMAD shared directory, there is a configuration file in the JSON format (`/SNS/NOM/shared/autoreduce/auto_config.json`) containing some common parameters shared across all measurements. Only NOMAD team members have the permission of editing and in fact, parameters included in the file are not expected to be changed frequently. Characterization runs information (typically, calibration file, container and empty instrument background, and vanadium normalization) is contained in `/SNS/NOM/shared/autoreduce/auto_exp.csv`. In case any of the two files are updated and we need to rerun the autoreduction, we can log into the ORNL Analysis (see here, analysis.sns.gov) and run the command like `all_nom 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. More detailed information can be found here, `https://powder.ornl.gov/auto_reduce/nomad_auto.html`.\n\nThe other level of configuration is measurement-specific, in which case individual measurements have to be processed individually based on the input JSON files created through the autoreduction routine. Those input files can be found in locations like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/multi_banks_summed/Input` or `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` on the ORNL Analysis cluster. The `multi_banks` mode here means the data would be grouped according to those physical banks of detectors. The `single_bank` mode means data from all detectors would be merged into a single pattern. The `summed` here in the path means all files corresponding to the same measurement are summed together. This is specific to the convention followed on NOMAD for the data collection -- usually, a long data collection would be done through multiple chunks of collection. For example, a total 8 C proton charge accumulation would be collected through 4 chunks, with each chunk contributing 2 C proton charge accumulation. Depending on which mode we want to go with (i.e., `multi_banks` or `single_bank`), we can go into the corresponding directory, make changes to the intended input file and run the data processing via `mts <input>.json` from a terminal (for sure, you need to run something like `cd /SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` to go to the directory first, in the terminal). `<input>.json` (without bracket) represents the input JSON file that you want to run. Usually, parameters like `Scale` in the `Background` entry of `Sample` or the `Type` entry in `AbsorptionCorrection` may be expected to be changed for the re-processing. Detailed information about the input file for running `MantidTotalScattering` (what the command `mts` is short for) can be found here, `https://powder.ornl.gov/total_scattering/data_reduction/mts_doc.html`.\n\nFor autoreduction and the processing with `all_nom`, output of reduced data can be found at something like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. For manual processing with `mts`, the output directory can be specified explicitly in the input JSON file."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: NOMAD\nQ: Reprocess NOMAD data for me.\nA: On NOMAD, there are two levels of parameter configuration for the autoreduction. In the NOMAD shared directory, there is a configuration file in the JSON format (`/SNS/NOM/shared/autoreduce/auto_config.json`) containing some common parameters shared across all measurements. Only NOMAD team members have the permission of editing and in fact, parameters included in the file are not expected to be changed frequently. Characterization runs information (typically, calibration file, container and empty instrument background, and vanadium normalization) is contained in `/SNS/NOM/shared/autoreduce/auto_exp.csv`. In case any of the two files are updated and we need to rerun the autoreduction, we can log into the ORNL Analysis (see here, analysis.sns.gov) and run the command like `all_nom 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. More detailed information can be found here, `https://powder.ornl.gov/auto_reduce/nomad_auto.html`.\n\nThe other level of configuration is measurement-specific, in which case individual measurements have to be processed individually based on the input JSON files created through the autoreduction routine. Those input files can be found in locations like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/multi_banks_summed/Input` or `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` on the ORNL Analysis cluster. The `multi_banks` mode here means the data would be grouped according to those physical banks of detectors. The `single_bank` mode means data from all detectors would be merged into a single pattern. The `summed` here in the path means all files corresponding to the same measurement are summed together. This is specific to the convention followed on NOMAD for the data collection -- usually, a long data collection would be done through multiple chunks of collection. For example, a total 8 C proton charge accumulation would be collected through 4 chunks, with each chunk contributing 2 C proton charge accumulation. Depending on which mode we want to go with (i.e., `multi_banks` or `single_bank`), we can go into the corresponding directory, make changes to the intended input file and run the data processing via `mts <input>.json` from a terminal (for sure, you need to run something like `cd /SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` to go to the directory first, in the terminal). `<input>.json` (without bracket) represents the input JSON file that you want to run. Usually, parameters like `Scale` in the `Background` entry of `Sample` or the `Type` entry in `AbsorptionCorrection` may be expected to be changed for the re-processing. Detailed information about the input file for running `MantidTotalScattering` (what the command `mts` is short for) can be found here, `https://powder.ornl.gov/total_scattering/data_reduction/mts_doc.html`.\n\nFor autoreduction and the processing with `all_nom`, output of reduced data can be found at something like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. For manual processing with `mts`, the output directory can be specified explicitly in the input JSON file."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: NOMAD\nQ: How can I rerun the processing on NOMAD?\nA: On NOMAD, there are two levels of parameter configuration for the autoreduction. In the NOMAD shared directory, there is a configuration file in the JSON format (`/SNS/NOM/shared/autoreduce/auto_config.json`) containing some common parameters shared across all measurements. Only NOMAD team members have the permission of editing and in fact, parameters included in the file are not expected to be changed frequently. Characterization runs information (typically, calibration file, container and empty instrument background, and vanadium normalization) is contained in `/SNS/NOM/shared/autoreduce/auto_exp.csv`. In case any of the two files are updated and we need to rerun the autoreduction, we can log into the ORNL Analysis (see here, analysis.sns.gov) and run the command like `all_nom 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. More detailed information can be found here, `https://powder.ornl.gov/auto_reduce/nomad_auto.html`.\n\nThe other level of configuration is measurement-specific, in which case individual measurements have to be processed individually based on the input JSON files created through the autoreduction routine. Those input files can be found in locations like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/multi_banks_summed/Input` or `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` on the ORNL Analysis cluster. The `multi_banks` mode here means the data would be grouped according to those physical banks of detectors. The `single_bank` mode means data from all detectors would be merged into a single pattern. The `summed` here in the path means all files corresponding to the same measurement are summed together. This is specific to the convention followed on NOMAD for the data collection -- usually, a long data collection would be done through multiple chunks of collection. For example, a total 8 C proton charge accumulation would be collected through 4 chunks, with each chunk contributing 2 C proton charge accumulation. Depending on which mode we want to go with (i.e., `multi_banks` or `single_bank`), we can go into the corresponding directory, make changes to the intended input file and run the data processing via `mts <input>.json` from a terminal (for sure, you need to run something like `cd /SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` to go to the directory first, in the terminal). `<input>.json` (without bracket) represents the input JSON file that you want to run. Usually, parameters like `Scale` in the `Background` entry of `Sample` or the `Type` entry in `AbsorptionCorrection` may be expected to be changed for the re-processing. Detailed information about the input file for running `MantidTotalScattering` (what the command `mts` is short for) can be found here, `https://powder.ornl.gov/total_scattering/data_reduction/mts_doc.html`.\n\nFor autoreduction and the processing with `all_nom`, output of reduced data can be found at something like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. For manual processing with `mts`, the output directory can be specified explicitly in the input JSON file."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: NOMAD\nQ: I want to rerun my NOMAD measurements.\nA: On NOMAD, there are two levels of parameter configuration for the autoreduction. In the NOMAD shared directory, there is a configuration file in the JSON format (`/SNS/NOM/shared/autoreduce/auto_config.json`) containing some common parameters shared across all measurements. Only NOMAD team members have the permission of editing and in fact, parameters included in the file are not expected to be changed frequently. Characterization runs information (typically, calibration file, container and empty instrument background, and vanadium normalization) is contained in `/SNS/NOM/shared/autoreduce/auto_exp.csv`. In case any of the two files are updated and we need to rerun the autoreduction, we can log into the ORNL Analysis (see here, analysis.sns.gov) and run the command like `all_nom 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. More detailed information can be found here, `https://powder.ornl.gov/auto_reduce/nomad_auto.html`.\n\nThe other level of configuration is measurement-specific, in which case individual measurements have to be processed individually based on the input JSON files created through the autoreduction routine. Those input files can be found in locations like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/multi_banks_summed/Input` or `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` on the ORNL Analysis cluster. The `multi_banks` mode here means the data would be grouped according to those physical banks of detectors. The `single_bank` mode means data from all detectors would be merged into a single pattern. The `summed` here in the path means all files corresponding to the same measurement are summed together. This is specific to the convention followed on NOMAD for the data collection -- usually, a long data collection would be done through multiple chunks of collection. For example, a total 8 C proton charge accumulation would be collected through 4 chunks, with each chunk contributing 2 C proton charge accumulation. Depending on which mode we want to go with (i.e., `multi_banks` or `single_bank`), we can go into the corresponding directory, make changes to the intended input file and run the data processing via `mts <input>.json` from a terminal (for sure, you need to run something like `cd /SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` to go to the directory first, in the terminal). `<input>.json` (without bracket) represents the input JSON file that you want to run. Usually, parameters like `Scale` in the `Background` entry of `Sample` or the `Type` entry in `AbsorptionCorrection` may be expected to be changed for the re-processing. Detailed information about the input file for running `MantidTotalScattering` (what the command `mts` is short for) can be found here, `https://powder.ornl.gov/total_scattering/data_reduction/mts_doc.html`.\n\nFor autoreduction and the processing with `all_nom`, output of reduced data can be found at something like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. For manual processing with `mts`, the output directory can be specified explicitly in the input JSON file."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: NOMAD\nQ: Tell me how to rerun NOMAD data reduction.\nA: On NOMAD, there are two levels of parameter configuration for the autoreduction. In the NOMAD shared directory, there is a configuration file in the JSON format (`/SNS/NOM/shared/autoreduce/auto_config.json`) containing some common parameters shared across all measurements. Only NOMAD team members have the permission of editing and in fact, parameters included in the file are not expected to be changed frequently. Characterization runs information (typically, calibration file, container and empty instrument background, and vanadium normalization) is contained in `/SNS/NOM/shared/autoreduce/auto_exp.csv`. In case any of the two files are updated and we need to rerun the autoreduction, we can log into the ORNL Analysis (see here, analysis.sns.gov) and run the command like `all_nom 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. More detailed information can be found here, `https://powder.ornl.gov/auto_reduce/nomad_auto.html`.\n\nThe other level of configuration is measurement-specific, in which case individual measurements have to be processed individually based on the input JSON files created through the autoreduction routine. Those input files can be found in locations like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/multi_banks_summed/Input` or `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` on the ORNL Analysis cluster. The `multi_banks` mode here means the data would be grouped according to those physical banks of detectors. The `single_bank` mode means data from all detectors would be merged into a single pattern. The `summed` here in the path means all files corresponding to the same measurement are summed together. This is specific to the convention followed on NOMAD for the data collection -- usually, a long data collection would be done through multiple chunks of collection. For example, a total 8 C proton charge accumulation would be collected through 4 chunks, with each chunk contributing 2 C proton charge accumulation. Depending on which mode we want to go with (i.e., `multi_banks` or `single_bank`), we can go into the corresponding directory, make changes to the intended input file and run the data processing via `mts <input>.json` from a terminal (for sure, you need to run something like `cd /SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` to go to the directory first, in the terminal). `<input>.json` (without bracket) represents the input JSON file that you want to run. Usually, parameters like `Scale` in the `Background` entry of `Sample` or the `Type` entry in `AbsorptionCorrection` may be expected to be changed for the re-processing. Detailed information about the input file for running `MantidTotalScattering` (what the command `mts` is short for) can be found here, `https://powder.ornl.gov/total_scattering/data_reduction/mts_doc.html`.\n\nFor autoreduction and the processing with `all_nom`, output of reduced data can be found at something like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. For manual processing with `mts`, the output directory can be specified explicitly in the input JSON file."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: NOMAD\nQ: I need help rerunning NOMAD processing.\nA: On NOMAD, there are two levels of parameter configuration for the autoreduction. In the NOMAD shared directory, there is a configuration file in the JSON format (`/SNS/NOM/shared/autoreduce/auto_config.json`) containing some common parameters shared across all measurements. Only NOMAD team members have the permission of editing and in fact, parameters included in the file are not expected to be changed frequently. Characterization runs information (typically, calibration file, container and empty instrument background, and vanadium normalization) is contained in `/SNS/NOM/shared/autoreduce/auto_exp.csv`. In case any of the two files are updated and we need to rerun the autoreduction, we can log into the ORNL Analysis (see here, analysis.sns.gov) and run the command like `all_nom 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. More detailed information can be found here, `https://powder.ornl.gov/auto_reduce/nomad_auto.html`.\n\nThe other level of configuration is measurement-specific, in which case individual measurements have to be processed individually based on the input JSON files created through the autoreduction routine. Those input files can be found in locations like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/multi_banks_summed/Input` or `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` on the ORNL Analysis cluster. The `multi_banks` mode here means the data would be grouped according to those physical banks of detectors. The `single_bank` mode means data from all detectors would be merged into a single pattern. The `summed` here in the path means all files corresponding to the same measurement are summed together. This is specific to the convention followed on NOMAD for the data collection -- usually, a long data collection would be done through multiple chunks of collection. For example, a total 8 C proton charge accumulation would be collected through 4 chunks, with each chunk contributing 2 C proton charge accumulation. Depending on which mode we want to go with (i.e., `multi_banks` or `single_bank`), we can go into the corresponding directory, make changes to the intended input file and run the data processing via `mts <input>.json` from a terminal (for sure, you need to run something like `cd /SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` to go to the directory first, in the terminal). `<input>.json` (without bracket) represents the input JSON file that you want to run. Usually, parameters like `Scale` in the `Background` entry of `Sample` or the `Type` entry in `AbsorptionCorrection` may be expected to be changed for the re-processing. Detailed information about the input file for running `MantidTotalScattering` (what the command `mts` is short for) can be found here, `https://powder.ornl.gov/total_scattering/data_reduction/mts_doc.html`.\n\nFor autoreduction and the processing with `all_nom`, output of reduced data can be found at something like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. For manual processing with `mts`, the output directory can be specified explicitly in the input JSON file."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: NOMAD\nQ: Rerun NOMAD data processing steps.\nA: On NOMAD, there are two levels of parameter configuration for the autoreduction. In the NOMAD shared directory, there is a configuration file in the JSON format (`/SNS/NOM/shared/autoreduce/auto_config.json`) containing some common parameters shared across all measurements. Only NOMAD team members have the permission of editing and in fact, parameters included in the file are not expected to be changed frequently. Characterization runs information (typically, calibration file, container and empty instrument background, and vanadium normalization) is contained in `/SNS/NOM/shared/autoreduce/auto_exp.csv`. In case any of the two files are updated and we need to rerun the autoreduction, we can log into the ORNL Analysis (see here, analysis.sns.gov) and run the command like `all_nom 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. More detailed information can be found here, `https://powder.ornl.gov/auto_reduce/nomad_auto.html`.\n\nThe other level of configuration is measurement-specific, in which case individual measurements have to be processed individually based on the input JSON files created through the autoreduction routine. Those input files can be found in locations like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/multi_banks_summed/Input` or `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` on the ORNL Analysis cluster. The `multi_banks` mode here means the data would be grouped according to those physical banks of detectors. The `single_bank` mode means data from all detectors would be merged into a single pattern. The `summed` here in the path means all files corresponding to the same measurement are summed together. This is specific to the convention followed on NOMAD for the data collection -- usually, a long data collection would be done through multiple chunks of collection. For example, a total 8 C proton charge accumulation would be collected through 4 chunks, with each chunk contributing 2 C proton charge accumulation. Depending on which mode we want to go with (i.e., `multi_banks` or `single_bank`), we can go into the corresponding directory, make changes to the intended input file and run the data processing via `mts <input>.json` from a terminal (for sure, you need to run something like `cd /SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` to go to the directory first, in the terminal). `<input>.json` (without bracket) represents the input JSON file that you want to run. Usually, parameters like `Scale` in the `Background` entry of `Sample` or the `Type` entry in `AbsorptionCorrection` may be expected to be changed for the re-processing. Detailed information about the input file for running `MantidTotalScattering` (what the command `mts` is short for) can be found here, `https://powder.ornl.gov/total_scattering/data_reduction/mts_doc.html`.\n\nFor autoreduction and the processing with `all_nom`, output of reduced data can be found at something like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. For manual processing with `mts`, the output directory can be specified explicitly in the input JSON file."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: NOMAD\nQ: Guide me through rerunning NOMAD autoreduction.\nA: On NOMAD, there are two levels of parameter configuration for the autoreduction. In the NOMAD shared directory, there is a configuration file in the JSON format (`/SNS/NOM/shared/autoreduce/auto_config.json`) containing some common parameters shared across all measurements. Only NOMAD team members have the permission of editing and in fact, parameters included in the file are not expected to be changed frequently. Characterization runs information (typically, calibration file, container and empty instrument background, and vanadium normalization) is contained in `/SNS/NOM/shared/autoreduce/auto_exp.csv`. In case any of the two files are updated and we need to rerun the autoreduction, we can log into the ORNL Analysis (see here, analysis.sns.gov) and run the command like `all_nom 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. More detailed information can be found here, `https://powder.ornl.gov/auto_reduce/nomad_auto.html`.\n\nThe other level of configuration is measurement-specific, in which case individual measurements have to be processed individually based on the input JSON files created through the autoreduction routine. Those input files can be found in locations like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/multi_banks_summed/Input` or `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` on the ORNL Analysis cluster. The `multi_banks` mode here means the data would be grouped according to those physical banks of detectors. The `single_bank` mode means data from all detectors would be merged into a single pattern. The `summed` here in the path means all files corresponding to the same measurement are summed together. This is specific to the convention followed on NOMAD for the data collection -- usually, a long data collection would be done through multiple chunks of collection. For example, a total 8 C proton charge accumulation would be collected through 4 chunks, with each chunk contributing 2 C proton charge accumulation. Depending on which mode we want to go with (i.e., `multi_banks` or `single_bank`), we can go into the corresponding directory, make changes to the intended input file and run the data processing via `mts <input>.json` from a terminal (for sure, you need to run something like `cd /SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` to go to the directory first, in the terminal). `<input>.json` (without bracket) represents the input JSON file that you want to run. Usually, parameters like `Scale` in the `Background` entry of `Sample` or the `Type` entry in `AbsorptionCorrection` may be expected to be changed for the re-processing. Detailed information about the input file for running `MantidTotalScattering` (what the command `mts` is short for) can be found here, `https://powder.ornl.gov/total_scattering/data_reduction/mts_doc.html`.\n\nFor autoreduction and the processing with `all_nom`, output of reduced data can be found at something like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. For manual processing with `mts`, the output directory can be specified explicitly in the input JSON file."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: NOMAD\nQ: How to reprocess NOMAD measurements?\nA: On NOMAD, there are two levels of parameter configuration for the autoreduction. In the NOMAD shared directory, there is a configuration file in the JSON format (`/SNS/NOM/shared/autoreduce/auto_config.json`) containing some common parameters shared across all measurements. Only NOMAD team members have the permission of editing and in fact, parameters included in the file are not expected to be changed frequently. Characterization runs information (typically, calibration file, container and empty instrument background, and vanadium normalization) is contained in `/SNS/NOM/shared/autoreduce/auto_exp.csv`. In case any of the two files are updated and we need to rerun the autoreduction, we can log into the ORNL Analysis (see here, analysis.sns.gov) and run the command like `all_nom 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. More detailed information can be found here, `https://powder.ornl.gov/auto_reduce/nomad_auto.html`.\n\nThe other level of configuration is measurement-specific, in which case individual measurements have to be processed individually based on the input JSON files created through the autoreduction routine. Those input files can be found in locations like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/multi_banks_summed/Input` or `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` on the ORNL Analysis cluster. The `multi_banks` mode here means the data would be grouped according to those physical banks of detectors. The `single_bank` mode means data from all detectors would be merged into a single pattern. The `summed` here in the path means all files corresponding to the same measurement are summed together. This is specific to the convention followed on NOMAD for the data collection -- usually, a long data collection would be done through multiple chunks of collection. For example, a total 8 C proton charge accumulation would be collected through 4 chunks, with each chunk contributing 2 C proton charge accumulation. Depending on which mode we want to go with (i.e., `multi_banks` or `single_bank`), we can go into the corresponding directory, make changes to the intended input file and run the data processing via `mts <input>.json` from a terminal (for sure, you need to run something like `cd /SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` to go to the directory first, in the terminal). `<input>.json` (without bracket) represents the input JSON file that you want to run. Usually, parameters like `Scale` in the `Background` entry of `Sample` or the `Type` entry in `AbsorptionCorrection` may be expected to be changed for the re-processing. Detailed information about the input file for running `MantidTotalScattering` (what the command `mts` is short for) can be found here, `https://powder.ornl.gov/total_scattering/data_reduction/mts_doc.html`.\n\nFor autoreduction and the processing with `all_nom`, output of reduced data can be found at something like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. For manual processing with `mts`, the output directory can be specified explicitly in the input JSON file."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: NOMAD\nQ: I want to redo NOMAD data processing.\nA: On NOMAD, there are two levels of parameter configuration for the autoreduction. In the NOMAD shared directory, there is a configuration file in the JSON format (`/SNS/NOM/shared/autoreduce/auto_config.json`) containing some common parameters shared across all measurements. Only NOMAD team members have the permission of editing and in fact, parameters included in the file are not expected to be changed frequently. Characterization runs information (typically, calibration file, container and empty instrument background, and vanadium normalization) is contained in `/SNS/NOM/shared/autoreduce/auto_exp.csv`. In case any of the two files are updated and we need to rerun the autoreduction, we can log into the ORNL Analysis (see here, analysis.sns.gov) and run the command like `all_nom 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. More detailed information can be found here, `https://powder.ornl.gov/auto_reduce/nomad_auto.html`.\n\nThe other level of configuration is measurement-specific, in which case individual measurements have to be processed individually based on the input JSON files created through the autoreduction routine. Those input files can be found in locations like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/multi_banks_summed/Input` or `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` on the ORNL Analysis cluster. The `multi_banks` mode here means the data would be grouped according to those physical banks of detectors. The `single_bank` mode means data from all detectors would be merged into a single pattern. The `summed` here in the path means all files corresponding to the same measurement are summed together. This is specific to the convention followed on NOMAD for the data collection -- usually, a long data collection would be done through multiple chunks of collection. For example, a total 8 C proton charge accumulation would be collected through 4 chunks, with each chunk contributing 2 C proton charge accumulation. Depending on which mode we want to go with (i.e., `multi_banks` or `single_bank`), we can go into the corresponding directory, make changes to the intended input file and run the data processing via `mts <input>.json` from a terminal (for sure, you need to run something like `cd /SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` to go to the directory first, in the terminal). `<input>.json` (without bracket) represents the input JSON file that you want to run. Usually, parameters like `Scale` in the `Background` entry of `Sample` or the `Type` entry in `AbsorptionCorrection` may be expected to be changed for the re-processing. Detailed information about the input file for running `MantidTotalScattering` (what the command `mts` is short for) can be found here, `https://powder.ornl.gov/total_scattering/data_reduction/mts_doc.html`.\n\nFor autoreduction and the processing with `all_nom`, output of reduced data can be found at something like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. For manual processing with `mts`, the output directory can be specified explicitly in the input JSON file."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: NOMAD\nQ: Rerun my NOMAD data analysis.\nA: On NOMAD, there are two levels of parameter configuration for the autoreduction. In the NOMAD shared directory, there is a configuration file in the JSON format (`/SNS/NOM/shared/autoreduce/auto_config.json`) containing some common parameters shared across all measurements. Only NOMAD team members have the permission of editing and in fact, parameters included in the file are not expected to be changed frequently. Characterization runs information (typically, calibration file, container and empty instrument background, and vanadium normalization) is contained in `/SNS/NOM/shared/autoreduce/auto_exp.csv`. In case any of the two files are updated and we need to rerun the autoreduction, we can log into the ORNL Analysis (see here, analysis.sns.gov) and run the command like `all_nom 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. More detailed information can be found here, `https://powder.ornl.gov/auto_reduce/nomad_auto.html`.\n\nThe other level of configuration is measurement-specific, in which case individual measurements have to be processed individually based on the input JSON files created through the autoreduction routine. Those input files can be found in locations like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/multi_banks_summed/Input` or `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` on the ORNL Analysis cluster. The `multi_banks` mode here means the data would be grouped according to those physical banks of detectors. The `single_bank` mode means data from all detectors would be merged into a single pattern. The `summed` here in the path means all files corresponding to the same measurement are summed together. This is specific to the convention followed on NOMAD for the data collection -- usually, a long data collection would be done through multiple chunks of collection. For example, a total 8 C proton charge accumulation would be collected through 4 chunks, with each chunk contributing 2 C proton charge accumulation. Depending on which mode we want to go with (i.e., `multi_banks` or `single_bank`), we can go into the corresponding directory, make changes to the intended input file and run the data processing via `mts <input>.json` from a terminal (for sure, you need to run something like `cd /SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` to go to the directory first, in the terminal). `<input>.json` (without bracket) represents the input JSON file that you want to run. Usually, parameters like `Scale` in the `Background` entry of `Sample` or the `Type` entry in `AbsorptionCorrection` may be expected to be changed for the re-processing. Detailed information about the input file for running `MantidTotalScattering` (what the command `mts` is short for) can be found here, `https://powder.ornl.gov/total_scattering/data_reduction/mts_doc.html`.\n\nFor autoreduction and the processing with `all_nom`, output of reduced data can be found at something like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. For manual processing with `mts`, the output directory can be specified explicitly in the input JSON file."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: NOMAD\nQ: Show me how to rerun NOMAD processing.\nA: On NOMAD, there are two levels of parameter configuration for the autoreduction. In the NOMAD shared directory, there is a configuration file in the JSON format (`/SNS/NOM/shared/autoreduce/auto_config.json`) containing some common parameters shared across all measurements. Only NOMAD team members have the permission of editing and in fact, parameters included in the file are not expected to be changed frequently. Characterization runs information (typically, calibration file, container and empty instrument background, and vanadium normalization) is contained in `/SNS/NOM/shared/autoreduce/auto_exp.csv`. In case any of the two files are updated and we need to rerun the autoreduction, we can log into the ORNL Analysis (see here, analysis.sns.gov) and run the command like `all_nom 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. More detailed information can be found here, `https://powder.ornl.gov/auto_reduce/nomad_auto.html`.\n\nThe other level of configuration is measurement-specific, in which case individual measurements have to be processed individually based on the input JSON files created through the autoreduction routine. Those input files can be found in locations like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/multi_banks_summed/Input` or `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` on the ORNL Analysis cluster. The `multi_banks` mode here means the data would be grouped according to those physical banks of detectors. The `single_bank` mode means data from all detectors would be merged into a single pattern. The `summed` here in the path means all files corresponding to the same measurement are summed together. This is specific to the convention followed on NOMAD for the data collection -- usually, a long data collection would be done through multiple chunks of collection. For example, a total 8 C proton charge accumulation would be collected through 4 chunks, with each chunk contributing 2 C proton charge accumulation. Depending on which mode we want to go with (i.e., `multi_banks` or `single_bank`), we can go into the corresponding directory, make changes to the intended input file and run the data processing via `mts <input>.json` from a terminal (for sure, you need to run something like `cd /SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` to go to the directory first, in the terminal). `<input>.json` (without bracket) represents the input JSON file that you want to run. Usually, parameters like `Scale` in the `Background` entry of `Sample` or the `Type` entry in `AbsorptionCorrection` may be expected to be changed for the re-processing. Detailed information about the input file for running `MantidTotalScattering` (what the command `mts` is short for) can be found here, `https://powder.ornl.gov/total_scattering/data_reduction/mts_doc.html`.\n\nFor autoreduction and the processing with `all_nom`, output of reduced data can be found at something like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. For manual processing with `mts`, the output directory can be specified explicitly in the input JSON file."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: NOMAD\nQ: I need to process my NOMAD data. Give me some information.\nA: Normally, the NOMAD autoreduction routine will take care of the data processing and reduced data can be found at `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. On NOMAD, there are two levels of parameter configuration for the autoreduction. In the NOMAD shared directory, there is a configuration file in the JSON format (`/SNS/NOM/shared/autoreduce/auto_config.json`) containing some common parameters shared across all measurements. Only NOMAD team members have the permission of editing and in fact, parameters included in the file are not expected to be changed frequently. Characterization runs information (typically, calibration file, container and empty instrument background, and vanadium normalization) is contained in `/SNS/NOM/shared/autoreduce/auto_exp.csv`. In case any of the two files are updated and we need to rerun the autoreduction, we can log into the ORNL Analysis (see here, analysis.sns.gov) and run the command like `all_nom 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. More detailed information can be found here, `https://powder.ornl.gov/auto_reduce/nomad_auto.html`.\n\nThe other level of configuration is measurement-specific, in which case individual measurements have to be processed individually based on the input JSON files created through the autoreduction routine. Those input files can be found in locations like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/multi_banks_summed/Input` or `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` on the ORNL Analysis cluster. The `multi_banks` mode here means the data would be grouped according to those physical banks of detectors. The `single_bank` mode means data from all detectors would be merged into a single pattern. The `summed` here in the path means all files corresponding to the same measurement are summed together. This is specific to the convention followed on NOMAD for the data collection -- usually, a long data collection would be done through multiple chunks of collection. For example, a total 8 C proton charge accumulation would be collected through 4 chunks, with each chunk contributing 2 C proton charge accumulation. Depending on which mode we want to go with (i.e., `multi_banks` or `single_bank`), we can go into the corresponding directory, make changes to the intended input file and run the data processing via `mts <input>.json` from a terminal (for sure, you need to run something like `cd /SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` to go to the directory first, in the terminal). `<input>.json` (without bracket) represents the input JSON file that you want to run. Usually, parameters like `Scale` in the `Background` entry of `Sample` or the `Type` entry in `AbsorptionCorrection` may be expected to be changed for the re-processing. Detailed information about the input file for running `MantidTotalScattering` (what the command `mts` is short for) can be found here, `https://powder.ornl.gov/total_scattering/data_reduction/mts_doc.html`.\n\nFor autoreduction and the processing with `all_nom`, output of reduced data can be found at something like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. For manual processing with `mts`, the output directory can be specified explicitly in the input JSON file."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: NOMAD\nQ: How do I process NOMAD data?\nA: Normally, the NOMAD autoreduction routine will take care of the data processing and reduced data can be found at `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. On NOMAD, there are two levels of parameter configuration for the autoreduction. In the NOMAD shared directory, there is a configuration file in the JSON format (`/SNS/NOM/shared/autoreduce/auto_config.json`) containing some common parameters shared across all measurements. Only NOMAD team members have the permission of editing and in fact, parameters included in the file are not expected to be changed frequently. Characterization runs information (typically, calibration file, container and empty instrument background, and vanadium normalization) is contained in `/SNS/NOM/shared/autoreduce/auto_exp.csv`. In case any of the two files are updated and we need to rerun the autoreduction, we can log into the ORNL Analysis (see here, analysis.sns.gov) and run the command like `all_nom 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. More detailed information can be found here, `https://powder.ornl.gov/auto_reduce/nomad_auto.html`.\n\nThe other level of configuration is measurement-specific, in which case individual measurements have to be processed individually based on the input JSON files created through the autoreduction routine. Those input files can be found in locations like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/multi_banks_summed/Input` or `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` on the ORNL Analysis cluster. The `multi_banks` mode here means the data would be grouped according to those physical banks of detectors. The `single_bank` mode means data from all detectors would be merged into a single pattern. The `summed` here in the path means all files corresponding to the same measurement are summed together. This is specific to the convention followed on NOMAD for the data collection -- usually, a long data collection would be done through multiple chunks of collection. For example, a total 8 C proton charge accumulation would be collected through 4 chunks, with each chunk contributing 2 C proton charge accumulation. Depending on which mode we want to go with (i.e., `multi_banks` or `single_bank`), we can go into the corresponding directory, make changes to the intended input file and run the data processing via `mts <input>.json` from a terminal (for sure, you need to run something like `cd /SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` to go to the directory first, in the terminal). `<input>.json` (without bracket) represents the input JSON file that you want to run. Usually, parameters like `Scale` in the `Background` entry of `Sample` or the `Type` entry in `AbsorptionCorrection` may be expected to be changed for the re-processing. Detailed information about the input file for running `MantidTotalScattering` (what the command `mts` is short for) can be found here, `https://powder.ornl.gov/total_scattering/data_reduction/mts_doc.html`.\n\nFor autoreduction and the processing with `all_nom`, output of reduced data can be found at something like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. For manual processing with `mts`, the output directory can be specified explicitly in the input JSON file."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: NOMAD\nQ: I want to process my NOMAD measurements.\nA: Normally, the NOMAD autoreduction routine will take care of the data processing and reduced data can be found at `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. On NOMAD, there are two levels of parameter configuration for the autoreduction. In the NOMAD shared directory, there is a configuration file in the JSON format (`/SNS/NOM/shared/autoreduce/auto_config.json`) containing some common parameters shared across all measurements. Only NOMAD team members have the permission of editing and in fact, parameters included in the file are not expected to be changed frequently. Characterization runs information (typically, calibration file, container and empty instrument background, and vanadium normalization) is contained in `/SNS/NOM/shared/autoreduce/auto_exp.csv`. In case any of the two files are updated and we need to rerun the autoreduction, we can log into the ORNL Analysis (see here, analysis.sns.gov) and run the command like `all_nom 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. More detailed information can be found here, `https://powder.ornl.gov/auto_reduce/nomad_auto.html`.\n\nThe other level of configuration is measurement-specific, in which case individual measurements have to be processed individually based on the input JSON files created through the autoreduction routine. Those input files can be found in locations like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/multi_banks_summed/Input` or `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` on the ORNL Analysis cluster. The `multi_banks` mode here means the data would be grouped according to those physical banks of detectors. The `single_bank` mode means data from all detectors would be merged into a single pattern. The `summed` here in the path means all files corresponding to the same measurement are summed together. This is specific to the convention followed on NOMAD for the data collection -- usually, a long data collection would be done through multiple chunks of collection. For example, a total 8 C proton charge accumulation would be collected through 4 chunks, with each chunk contributing 2 C proton charge accumulation. Depending on which mode we want to go with (i.e., `multi_banks` or `single_bank`), we can go into the corresponding directory, make changes to the intended input file and run the data processing via `mts <input>.json` from a terminal (for sure, you need to run something like `cd /SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` to go to the directory first, in the terminal). `<input>.json` (without bracket) represents the input JSON file that you want to run. Usually, parameters like `Scale` in the `Background` entry of `Sample` or the `Type` entry in `AbsorptionCorrection` may be expected to be changed for the re-processing. Detailed information about the input file for running `MantidTotalScattering` (what the command `mts` is short for) can be found here, `https://powder.ornl.gov/total_scattering/data_reduction/mts_doc.html`.\n\nFor autoreduction and the processing with `all_nom`, output of reduced data can be found at something like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. For manual processing with `mts`, the output directory can be specified explicitly in the input JSON file."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: NOMAD\nQ: Tell me about NOMAD data processing.\nA: Normally, the NOMAD autoreduction routine will take care of the data processing and reduced data can be found at `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. On NOMAD, there are two levels of parameter configuration for the autoreduction. In the NOMAD shared directory, there is a configuration file in the JSON format (`/SNS/NOM/shared/autoreduce/auto_config.json`) containing some common parameters shared across all measurements. Only NOMAD team members have the permission of editing and in fact, parameters included in the file are not expected to be changed frequently. Characterization runs information (typically, calibration file, container and empty instrument background, and vanadium normalization) is contained in `/SNS/NOM/shared/autoreduce/auto_exp.csv`. In case any of the two files are updated and we need to rerun the autoreduction, we can log into the ORNL Analysis (see here, analysis.sns.gov) and run the command like `all_nom 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. More detailed information can be found here, `https://powder.ornl.gov/auto_reduce/nomad_auto.html`.\n\nThe other level of configuration is measurement-specific, in which case individual measurements have to be processed individually based on the input JSON files created through the autoreduction routine. Those input files can be found in locations like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/multi_banks_summed/Input` or `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` on the ORNL Analysis cluster. The `multi_banks` mode here means the data would be grouped according to those physical banks of detectors. The `single_bank` mode means data from all detectors would be merged into a single pattern. The `summed` here in the path means all files corresponding to the same measurement are summed together. This is specific to the convention followed on NOMAD for the data collection -- usually, a long data collection would be done through multiple chunks of collection. For example, a total 8 C proton charge accumulation would be collected through 4 chunks, with each chunk contributing 2 C proton charge accumulation. Depending on which mode we want to go with (i.e., `multi_banks` or `single_bank`), we can go into the corresponding directory, make changes to the intended input file and run the data processing via `mts <input>.json` from a terminal (for sure, you need to run something like `cd /SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` to go to the directory first, in the terminal). `<input>.json` (without bracket) represents the input JSON file that you want to run. Usually, parameters like `Scale` in the `Background` entry of `Sample` or the `Type` entry in `AbsorptionCorrection` may be expected to be changed for the re-processing. Detailed information about the input file for running `MantidTotalScattering` (what the command `mts` is short for) can be found here, `https://powder.ornl.gov/total_scattering/data_reduction/mts_doc.html`.\n\nFor autoreduction and the processing with `all_nom`, output of reduced data can be found at something like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. For manual processing with `mts`, the output directory can be specified explicitly in the input JSON file."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: NOMAD\nQ: How can I process data from NOMAD?\nA: Normally, the NOMAD autoreduction routine will take care of the data processing and reduced data can be found at `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. On NOMAD, there are two levels of parameter configuration for the autoreduction. In the NOMAD shared directory, there is a configuration file in the JSON format (`/SNS/NOM/shared/autoreduce/auto_config.json`) containing some common parameters shared across all measurements. Only NOMAD team members have the permission of editing and in fact, parameters included in the file are not expected to be changed frequently. Characterization runs information (typically, calibration file, container and empty instrument background, and vanadium normalization) is contained in `/SNS/NOM/shared/autoreduce/auto_exp.csv`. In case any of the two files are updated and we need to rerun the autoreduction, we can log into the ORNL Analysis (see here, analysis.sns.gov) and run the command like `all_nom 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. More detailed information can be found here, `https://powder.ornl.gov/auto_reduce/nomad_auto.html`.\n\nThe other level of configuration is measurement-specific, in which case individual measurements have to be processed individually based on the input JSON files created through the autoreduction routine. Those input files can be found in locations like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/multi_banks_summed/Input` or `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` on the ORNL Analysis cluster. The `multi_banks` mode here means the data would be grouped according to those physical banks of detectors. The `single_bank` mode means data from all detectors would be merged into a single pattern. The `summed` here in the path means all files corresponding to the same measurement are summed together. This is specific to the convention followed on NOMAD for the data collection -- usually, a long data collection would be done through multiple chunks of collection. For example, a total 8 C proton charge accumulation would be collected through 4 chunks, with each chunk contributing 2 C proton charge accumulation. Depending on which mode we want to go with (i.e., `multi_banks` or `single_bank`), we can go into the corresponding directory, make changes to the intended input file and run the data processing via `mts <input>.json` from a terminal (for sure, you need to run something like `cd /SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` to go to the directory first, in the terminal). `<input>.json` (without bracket) represents the input JSON file that you want to run. Usually, parameters like `Scale` in the `Background` entry of `Sample` or the `Type` entry in `AbsorptionCorrection` may be expected to be changed for the re-processing. Detailed information about the input file for running `MantidTotalScattering` (what the command `mts` is short for) can be found here, `https://powder.ornl.gov/total_scattering/data_reduction/mts_doc.html`.\n\nFor autoreduction and the processing with `all_nom`, output of reduced data can be found at something like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. For manual processing with `mts`, the output directory can be specified explicitly in the input JSON file."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: NOMAD\nQ: I need help with NOMAD data reduction.\nA: Normally, the NOMAD autoreduction routine will take care of the data processing and reduced data can be found at `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. On NOMAD, there are two levels of parameter configuration for the autoreduction. In the NOMAD shared directory, there is a configuration file in the JSON format (`/SNS/NOM/shared/autoreduce/auto_config.json`) containing some common parameters shared across all measurements. Only NOMAD team members have the permission of editing and in fact, parameters included in the file are not expected to be changed frequently. Characterization runs information (typically, calibration file, container and empty instrument background, and vanadium normalization) is contained in `/SNS/NOM/shared/autoreduce/auto_exp.csv`. In case any of the two files are updated and we need to rerun the autoreduction, we can log into the ORNL Analysis (see here, analysis.sns.gov) and run the command like `all_nom 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. More detailed information can be found here, `https://powder.ornl.gov/auto_reduce/nomad_auto.html`.\n\nThe other level of configuration is measurement-specific, in which case individual measurements have to be processed individually based on the input JSON files created through the autoreduction routine. Those input files can be found in locations like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/multi_banks_summed/Input` or `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` on the ORNL Analysis cluster. The `multi_banks` mode here means the data would be grouped according to those physical banks of detectors. The `single_bank` mode means data from all detectors would be merged into a single pattern. The `summed` here in the path means all files corresponding to the same measurement are summed together. This is specific to the convention followed on NOMAD for the data collection -- usually, a long data collection would be done through multiple chunks of collection. For example, a total 8 C proton charge accumulation would be collected through 4 chunks, with each chunk contributing 2 C proton charge accumulation. Depending on which mode we want to go with (i.e., `multi_banks` or `single_bank`), we can go into the corresponding directory, make changes to the intended input file and run the data processing via `mts <input>.json` from a terminal (for sure, you need to run something like `cd /SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` to go to the directory first, in the terminal). `<input>.json` (without bracket) represents the input JSON file that you want to run. Usually, parameters like `Scale` in the `Background` entry of `Sample` or the `Type` entry in `AbsorptionCorrection` may be expected to be changed for the re-processing. Detailed information about the input file for running `MantidTotalScattering` (what the command `mts` is short for) can be found here, `https://powder.ornl.gov/total_scattering/data_reduction/mts_doc.html`.\n\nFor autoreduction and the processing with `all_nom`, output of reduced data can be found at something like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. For manual processing with `mts`, the output directory can be specified explicitly in the input JSON file."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: NOMAD\nQ: Process my NOMAD data.\nA: Normally, the NOMAD autoreduction routine will take care of the data processing and reduced data can be found at `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. On NOMAD, there are two levels of parameter configuration for the autoreduction. In the NOMAD shared directory, there is a configuration file in the JSON format (`/SNS/NOM/shared/autoreduce/auto_config.json`) containing some common parameters shared across all measurements. Only NOMAD team members have the permission of editing and in fact, parameters included in the file are not expected to be changed frequently. Characterization runs information (typically, calibration file, container and empty instrument background, and vanadium normalization) is contained in `/SNS/NOM/shared/autoreduce/auto_exp.csv`. In case any of the two files are updated and we need to rerun the autoreduction, we can log into the ORNL Analysis (see here, analysis.sns.gov) and run the command like `all_nom 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. More detailed information can be found here, `https://powder.ornl.gov/auto_reduce/nomad_auto.html`.\n\nThe other level of configuration is measurement-specific, in which case individual measurements have to be processed individually based on the input JSON files created through the autoreduction routine. Those input files can be found in locations like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/multi_banks_summed/Input` or `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` on the ORNL Analysis cluster. The `multi_banks` mode here means the data would be grouped according to those physical banks of detectors. The `single_bank` mode means data from all detectors would be merged into a single pattern. The `summed` here in the path means all files corresponding to the same measurement are summed together. This is specific to the convention followed on NOMAD for the data collection -- usually, a long data collection would be done through multiple chunks of collection. For example, a total 8 C proton charge accumulation would be collected through 4 chunks, with each chunk contributing 2 C proton charge accumulation. Depending on which mode we want to go with (i.e., `multi_banks` or `single_bank`), we can go into the corresponding directory, make changes to the intended input file and run the data processing via `mts <input>.json` from a terminal (for sure, you need to run something like `cd /SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` to go to the directory first, in the terminal). `<input>.json` (without bracket) represents the input JSON file that you want to run. Usually, parameters like `Scale` in the `Background` entry of `Sample` or the `Type` entry in `AbsorptionCorrection` may be expected to be changed for the re-processing. Detailed information about the input file for running `MantidTotalScattering` (what the command `mts` is short for) can be found here, `https://powder.ornl.gov/total_scattering/data_reduction/mts_doc.html`.\n\nFor autoreduction and the processing with `all_nom`, output of reduced data can be found at something like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. For manual processing with `mts`, the output directory can be specified explicitly in the input JSON file."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: NOMAD\nQ: What's the procedure for NOMAD data processing?\nA: Normally, the NOMAD autoreduction routine will take care of the data processing and reduced data can be found at `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. On NOMAD, there are two levels of parameter configuration for the autoreduction. In the NOMAD shared directory, there is a configuration file in the JSON format (`/SNS/NOM/shared/autoreduce/auto_config.json`) containing some common parameters shared across all measurements. Only NOMAD team members have the permission of editing and in fact, parameters included in the file are not expected to be changed frequently. Characterization runs information (typically, calibration file, container and empty instrument background, and vanadium normalization) is contained in `/SNS/NOM/shared/autoreduce/auto_exp.csv`. In case any of the two files are updated and we need to rerun the autoreduction, we can log into the ORNL Analysis (see here, analysis.sns.gov) and run the command like `all_nom 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. More detailed information can be found here, `https://powder.ornl.gov/auto_reduce/nomad_auto.html`.\n\nThe other level of configuration is measurement-specific, in which case individual measurements have to be processed individually based on the input JSON files created through the autoreduction routine. Those input files can be found in locations like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/multi_banks_summed/Input` or `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` on the ORNL Analysis cluster. The `multi_banks` mode here means the data would be grouped according to those physical banks of detectors. The `single_bank` mode means data from all detectors would be merged into a single pattern. The `summed` here in the path means all files corresponding to the same measurement are summed together. This is specific to the convention followed on NOMAD for the data collection -- usually, a long data collection would be done through multiple chunks of collection. For example, a total 8 C proton charge accumulation would be collected through 4 chunks, with each chunk contributing 2 C proton charge accumulation. Depending on which mode we want to go with (i.e., `multi_banks` or `single_bank`), we can go into the corresponding directory, make changes to the intended input file and run the data processing via `mts <input>.json` from a terminal (for sure, you need to run something like `cd /SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` to go to the directory first, in the terminal). `<input>.json` (without bracket) represents the input JSON file that you want to run. Usually, parameters like `Scale` in the `Background` entry of `Sample` or the `Type` entry in `AbsorptionCorrection` may be expected to be changed for the re-processing. Detailed information about the input file for running `MantidTotalScattering` (what the command `mts` is short for) can be found here, `https://powder.ornl.gov/total_scattering/data_reduction/mts_doc.html`.\n\nFor autoreduction and the processing with `all_nom`, output of reduced data can be found at something like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. For manual processing with `mts`, the output directory can be specified explicitly in the input JSON file."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: NOMAD\nQ: I want to reduce NOMAD data.\nA: Normally, the NOMAD autoreduction routine will take care of the data processing and reduced data can be found at `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. On NOMAD, there are two levels of parameter configuration for the autoreduction. In the NOMAD shared directory, there is a configuration file in the JSON format (`/SNS/NOM/shared/autoreduce/auto_config.json`) containing some common parameters shared across all measurements. Only NOMAD team members have the permission of editing and in fact, parameters included in the file are not expected to be changed frequently. Characterization runs information (typically, calibration file, container and empty instrument background, and vanadium normalization) is contained in `/SNS/NOM/shared/autoreduce/auto_exp.csv`. In case any of the two files are updated and we need to rerun the autoreduction, we can log into the ORNL Analysis (see here, analysis.sns.gov) and run the command like `all_nom 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. More detailed information can be found here, `https://powder.ornl.gov/auto_reduce/nomad_auto.html`.\n\nThe other level of configuration is measurement-specific, in which case individual measurements have to be processed individually based on the input JSON files created through the autoreduction routine. Those input files can be found in locations like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/multi_banks_summed/Input` or `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` on the ORNL Analysis cluster. The `multi_banks` mode here means the data would be grouped according to those physical banks of detectors. The `single_bank` mode means data from all detectors would be merged into a single pattern. The `summed` here in the path means all files corresponding to the same measurement are summed together. This is specific to the convention followed on NOMAD for the data collection -- usually, a long data collection would be done through multiple chunks of collection. For example, a total 8 C proton charge accumulation would be collected through 4 chunks, with each chunk contributing 2 C proton charge accumulation. Depending on which mode we want to go with (i.e., `multi_banks` or `single_bank`), we can go into the corresponding directory, make changes to the intended input file and run the data processing via `mts <input>.json` from a terminal (for sure, you need to run something like `cd /SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` to go to the directory first, in the terminal). `<input>.json` (without bracket) represents the input JSON file that you want to run. Usually, parameters like `Scale` in the `Background` entry of `Sample` or the `Type` entry in `AbsorptionCorrection` may be expected to be changed for the re-processing. Detailed information about the input file for running `MantidTotalScattering` (what the command `mts` is short for) can be found here, `https://powder.ornl.gov/total_scattering/data_reduction/mts_doc.html`.\n\nFor autoreduction and the processing with `all_nom`, output of reduced data can be found at something like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. For manual processing with `mts`, the output directory can be specified explicitly in the input JSON file."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: NOMAD\nQ: Guide me through NOMAD data processing.\nA: Normally, the NOMAD autoreduction routine will take care of the data processing and reduced data can be found at `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. On NOMAD, there are two levels of parameter configuration for the autoreduction. In the NOMAD shared directory, there is a configuration file in the JSON format (`/SNS/NOM/shared/autoreduce/auto_config.json`) containing some common parameters shared across all measurements. Only NOMAD team members have the permission of editing and in fact, parameters included in the file are not expected to be changed frequently. Characterization runs information (typically, calibration file, container and empty instrument background, and vanadium normalization) is contained in `/SNS/NOM/shared/autoreduce/auto_exp.csv`. In case any of the two files are updated and we need to rerun the autoreduction, we can log into the ORNL Analysis (see here, analysis.sns.gov) and run the command like `all_nom 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. More detailed information can be found here, `https://powder.ornl.gov/auto_reduce/nomad_auto.html`.\n\nThe other level of configuration is measurement-specific, in which case individual measurements have to be processed individually based on the input JSON files created through the autoreduction routine. Those input files can be found in locations like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/multi_banks_summed/Input` or `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` on the ORNL Analysis cluster. The `multi_banks` mode here means the data would be grouped according to those physical banks of detectors. The `single_bank` mode means data from all detectors would be merged into a single pattern. The `summed` here in the path means all files corresponding to the same measurement are summed together. This is specific to the convention followed on NOMAD for the data collection -- usually, a long data collection would be done through multiple chunks of collection. For example, a total 8 C proton charge accumulation would be collected through 4 chunks, with each chunk contributing 2 C proton charge accumulation. Depending on which mode we want to go with (i.e., `multi_banks` or `single_bank`), we can go into the corresponding directory, make changes to the intended input file and run the data processing via `mts <input>.json` from a terminal (for sure, you need to run something like `cd /SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` to go to the directory first, in the terminal). `<input>.json` (without bracket) represents the input JSON file that you want to run. Usually, parameters like `Scale` in the `Background` entry of `Sample` or the `Type` entry in `AbsorptionCorrection` may be expected to be changed for the re-processing. Detailed information about the input file for running `MantidTotalScattering` (what the command `mts` is short for) can be found here, `https://powder.ornl.gov/total_scattering/data_reduction/mts_doc.html`.\n\nFor autoreduction and the processing with `all_nom`, output of reduced data can be found at something like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. For manual processing with `mts`, the output directory can be specified explicitly in the input JSON file."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: NOMAD\nQ: How to handle NOMAD data reduction?\nA: Normally, the NOMAD autoreduction routine will take care of the data processing and reduced data can be found at `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. On NOMAD, there are two levels of parameter configuration for the autoreduction. In the NOMAD shared directory, there is a configuration file in the JSON format (`/SNS/NOM/shared/autoreduce/auto_config.json`) containing some common parameters shared across all measurements. Only NOMAD team members have the permission of editing and in fact, parameters included in the file are not expected to be changed frequently. Characterization runs information (typically, calibration file, container and empty instrument background, and vanadium normalization) is contained in `/SNS/NOM/shared/autoreduce/auto_exp.csv`. In case any of the two files are updated and we need to rerun the autoreduction, we can log into the ORNL Analysis (see here, analysis.sns.gov) and run the command like `all_nom 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. More detailed information can be found here, `https://powder.ornl.gov/auto_reduce/nomad_auto.html`.\n\nThe other level of configuration is measurement-specific, in which case individual measurements have to be processed individually based on the input JSON files created through the autoreduction routine. Those input files can be found in locations like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/multi_banks_summed/Input` or `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` on the ORNL Analysis cluster. The `multi_banks` mode here means the data would be grouped according to those physical banks of detectors. The `single_bank` mode means data from all detectors would be merged into a single pattern. The `summed` here in the path means all files corresponding to the same measurement are summed together. This is specific to the convention followed on NOMAD for the data collection -- usually, a long data collection would be done through multiple chunks of collection. For example, a total 8 C proton charge accumulation would be collected through 4 chunks, with each chunk contributing 2 C proton charge accumulation. Depending on which mode we want to go with (i.e., `multi_banks` or `single_bank`), we can go into the corresponding directory, make changes to the intended input file and run the data processing via `mts <input>.json` from a terminal (for sure, you need to run something like `cd /SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` to go to the directory first, in the terminal). `<input>.json` (without bracket) represents the input JSON file that you want to run. Usually, parameters like `Scale` in the `Background` entry of `Sample` or the `Type` entry in `AbsorptionCorrection` may be expected to be changed for the re-processing. Detailed information about the input file for running `MantidTotalScattering` (what the command `mts` is short for) can be found here, `https://powder.ornl.gov/total_scattering/data_reduction/mts_doc.html`.\n\nFor autoreduction and the processing with `all_nom`, output of reduced data can be found at something like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. For manual processing with `mts`, the output directory can be specified explicitly in the input JSON file."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: NOMAD\nQ: I need information on NOMAD data processing.\nA: Normally, the NOMAD autoreduction routine will take care of the data processing and reduced data can be found at `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. On NOMAD, there are two levels of parameter configuration for the autoreduction. In the NOMAD shared directory, there is a configuration file in the JSON format (`/SNS/NOM/shared/autoreduce/auto_config.json`) containing some common parameters shared across all measurements. Only NOMAD team members have the permission of editing and in fact, parameters included in the file are not expected to be changed frequently. Characterization runs information (typically, calibration file, container and empty instrument background, and vanadium normalization) is contained in `/SNS/NOM/shared/autoreduce/auto_exp.csv`. In case any of the two files are updated and we need to rerun the autoreduction, we can log into the ORNL Analysis (see here, analysis.sns.gov) and run the command like `all_nom 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. More detailed information can be found here, `https://powder.ornl.gov/auto_reduce/nomad_auto.html`.\n\nThe other level of configuration is measurement-specific, in which case individual measurements have to be processed individually based on the input JSON files created through the autoreduction routine. Those input files can be found in locations like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/multi_banks_summed/Input` or `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` on the ORNL Analysis cluster. The `multi_banks` mode here means the data would be grouped according to those physical banks of detectors. The `single_bank` mode means data from all detectors would be merged into a single pattern. The `summed` here in the path means all files corresponding to the same measurement are summed together. This is specific to the convention followed on NOMAD for the data collection -- usually, a long data collection would be done through multiple chunks of collection. For example, a total 8 C proton charge accumulation would be collected through 4 chunks, with each chunk contributing 2 C proton charge accumulation. Depending on which mode we want to go with (i.e., `multi_banks` or `single_bank`), we can go into the corresponding directory, make changes to the intended input file and run the data processing via `mts <input>.json` from a terminal (for sure, you need to run something like `cd /SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` to go to the directory first, in the terminal). `<input>.json` (without bracket) represents the input JSON file that you want to run. Usually, parameters like `Scale` in the `Background` entry of `Sample` or the `Type` entry in `AbsorptionCorrection` may be expected to be changed for the re-processing. Detailed information about the input file for running `MantidTotalScattering` (what the command `mts` is short for) can be found here, `https://powder.ornl.gov/total_scattering/data_reduction/mts_doc.html`.\n\nFor autoreduction and the processing with `all_nom`, output of reduced data can be found at something like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. For manual processing with `mts`, the output directory can be specified explicitly in the input JSON file."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: NOMAD\nQ: Explain NOMAD data processing steps.\nA: Normally, the NOMAD autoreduction routine will take care of the data processing and reduced data can be found at `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. On NOMAD, there are two levels of parameter configuration for the autoreduction. In the NOMAD shared directory, there is a configuration file in the JSON format (`/SNS/NOM/shared/autoreduce/auto_config.json`) containing some common parameters shared across all measurements. Only NOMAD team members have the permission of editing and in fact, parameters included in the file are not expected to be changed frequently. Characterization runs information (typically, calibration file, container and empty instrument background, and vanadium normalization) is contained in `/SNS/NOM/shared/autoreduce/auto_exp.csv`. In case any of the two files are updated and we need to rerun the autoreduction, we can log into the ORNL Analysis (see here, analysis.sns.gov) and run the command like `all_nom 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. More detailed information can be found here, `https://powder.ornl.gov/auto_reduce/nomad_auto.html`.\n\nThe other level of configuration is measurement-specific, in which case individual measurements have to be processed individually based on the input JSON files created through the autoreduction routine. Those input files can be found in locations like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/multi_banks_summed/Input` or `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` on the ORNL Analysis cluster. The `multi_banks` mode here means the data would be grouped according to those physical banks of detectors. The `single_bank` mode means data from all detectors would be merged into a single pattern. The `summed` here in the path means all files corresponding to the same measurement are summed together. This is specific to the convention followed on NOMAD for the data collection -- usually, a long data collection would be done through multiple chunks of collection. For example, a total 8 C proton charge accumulation would be collected through 4 chunks, with each chunk contributing 2 C proton charge accumulation. Depending on which mode we want to go with (i.e., `multi_banks` or `single_bank`), we can go into the corresponding directory, make changes to the intended input file and run the data processing via `mts <input>.json` from a terminal (for sure, you need to run something like `cd /SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` to go to the directory first, in the terminal). `<input>.json` (without bracket) represents the input JSON file that you want to run. Usually, parameters like `Scale` in the `Background` entry of `Sample` or the `Type` entry in `AbsorptionCorrection` may be expected to be changed for the re-processing. Detailed information about the input file for running `MantidTotalScattering` (what the command `mts` is short for) can be found here, `https://powder.ornl.gov/total_scattering/data_reduction/mts_doc.html`.\n\nFor autoreduction and the processing with `all_nom`, output of reduced data can be found at something like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. For manual processing with `mts`, the output directory can be specified explicitly in the input JSON file."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: NOMAD\nQ: How do I reduce my NOMAD data?\nA: Normally, the NOMAD autoreduction routine will take care of the data processing and reduced data can be found at `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. On NOMAD, there are two levels of parameter configuration for the autoreduction. In the NOMAD shared directory, there is a configuration file in the JSON format (`/SNS/NOM/shared/autoreduce/auto_config.json`) containing some common parameters shared across all measurements. Only NOMAD team members have the permission of editing and in fact, parameters included in the file are not expected to be changed frequently. Characterization runs information (typically, calibration file, container and empty instrument background, and vanadium normalization) is contained in `/SNS/NOM/shared/autoreduce/auto_exp.csv`. In case any of the two files are updated and we need to rerun the autoreduction, we can log into the ORNL Analysis (see here, analysis.sns.gov) and run the command like `all_nom 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. More detailed information can be found here, `https://powder.ornl.gov/auto_reduce/nomad_auto.html`.\n\nThe other level of configuration is measurement-specific, in which case individual measurements have to be processed individually based on the input JSON files created through the autoreduction routine. Those input files can be found in locations like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/multi_banks_summed/Input` or `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` on the ORNL Analysis cluster. The `multi_banks` mode here means the data would be grouped according to those physical banks of detectors. The `single_bank` mode means data from all detectors would be merged into a single pattern. The `summed` here in the path means all files corresponding to the same measurement are summed together. This is specific to the convention followed on NOMAD for the data collection -- usually, a long data collection would be done through multiple chunks of collection. For example, a total 8 C proton charge accumulation would be collected through 4 chunks, with each chunk contributing 2 C proton charge accumulation. Depending on which mode we want to go with (i.e., `multi_banks` or `single_bank`), we can go into the corresponding directory, make changes to the intended input file and run the data processing via `mts <input>.json` from a terminal (for sure, you need to run something like `cd /SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` to go to the directory first, in the terminal). `<input>.json` (without bracket) represents the input JSON file that you want to run. Usually, parameters like `Scale` in the `Background` entry of `Sample` or the `Type` entry in `AbsorptionCorrection` may be expected to be changed for the re-processing. Detailed information about the input file for running `MantidTotalScattering` (what the command `mts` is short for) can be found here, `https://powder.ornl.gov/total_scattering/data_reduction/mts_doc.html`.\n\nFor autoreduction and the processing with `all_nom`, output of reduced data can be found at something like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. For manual processing with `mts`, the output directory can be specified explicitly in the input JSON file."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: NOMAD\nQ: Tell me about processing data on NOMAD.\nA: Normally, the NOMAD autoreduction routine will take care of the data processing and reduced data can be found at `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. On NOMAD, there are two levels of parameter configuration for the autoreduction. In the NOMAD shared directory, there is a configuration file in the JSON format (`/SNS/NOM/shared/autoreduce/auto_config.json`) containing some common parameters shared across all measurements. Only NOMAD team members have the permission of editing and in fact, parameters included in the file are not expected to be changed frequently. Characterization runs information (typically, calibration file, container and empty instrument background, and vanadium normalization) is contained in `/SNS/NOM/shared/autoreduce/auto_exp.csv`. In case any of the two files are updated and we need to rerun the autoreduction, we can log into the ORNL Analysis (see here, analysis.sns.gov) and run the command like `all_nom 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. The command is accessible in terminal on the ORNL Analysis cluster. Processed data will be saved into `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. More detailed information can be found here, `https://powder.ornl.gov/auto_reduce/nomad_auto.html`.\n\nThe other level of configuration is measurement-specific, in which case individual measurements have to be processed individually based on the input JSON files created through the autoreduction routine. Those input files can be found in locations like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/multi_banks_summed/Input` or `/SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` on the ORNL Analysis cluster. The `multi_banks` mode here means the data would be grouped according to those physical banks of detectors. The `single_bank` mode means data from all detectors would be merged into a single pattern. The `summed` here in the path means all files corresponding to the same measurement are summed together. This is specific to the convention followed on NOMAD for the data collection -- usually, a long data collection would be done through multiple chunks of collection. For example, a total 8 C proton charge accumulation would be collected through 4 chunks, with each chunk contributing 2 C proton charge accumulation. Depending on which mode we want to go with (i.e., `multi_banks` or `single_bank`), we can go into the corresponding directory, make changes to the intended input file and run the data processing via `mts <input>.json` from a terminal (for sure, you need to run something like `cd /SNS/NOM/IPTS-xxxxx/shared/autoreduce/single_bank_summed/Input` to go to the directory first, in the terminal). `<input>.json` (without bracket) represents the input JSON file that you want to run. Usually, parameters like `Scale` in the `Background` entry of `Sample` or the `Type` entry in `AbsorptionCorrection` may be expected to be changed for the re-processing. Detailed information about the input file for running `MantidTotalScattering` (what the command `mts` is short for) can be found here, `https://powder.ornl.gov/total_scattering/data_reduction/mts_doc.html`.\n\nFor autoreduction and the processing with `all_nom`, output of reduced data can be found at something like `/SNS/NOM/IPTS-xxxxx/shared/autoreduce`. For manual processing with `mts`, the output directory can be specified explicitly in the input JSON file."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2C\nQ: I need to rerun the processing for my HB2C data. Give me some information.\nA: On HB2C, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. Multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the HB2C shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the HB2C team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2C\nQ: I want to reprocess my HB2C data.\nA: On HB2C, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. Multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the HB2C shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the HB2C team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2C\nQ: How do I rerun HB2C data processing?\nA: On HB2C, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. Multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the HB2C shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the HB2C team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2C\nQ: I need to rerun HB2C autoreduction.\nA: On HB2C, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. Multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the HB2C shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the HB2C team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2C\nQ: Reprocess HB2C data for me.\nA: On HB2C, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. Multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the HB2C shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the HB2C team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2C\nQ: How can I rerun the processing on HB2C?\nA: On HB2C, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. Multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the HB2C shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the HB2C team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2C\nQ: I want to rerun my HB2C measurements.\nA: On HB2C, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. Multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the HB2C shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the HB2C team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2C\nQ: Tell me how to rerun HB2C data reduction.\nA: On HB2C, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. Multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the HB2C shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the HB2C team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2C\nQ: I need help rerunning HB2C processing.\nA: On HB2C, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. Multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the HB2C shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the HB2C team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2C\nQ: Rerun HB2C data processing steps.\nA: On HB2C, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. Multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the HB2C shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the HB2C team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2C\nQ: Guide me through rerunning HB2C autoreduction.\nA: On HB2C, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. Multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the HB2C shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the HB2C team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2C\nQ: How to reprocess HB2C measurements?\nA: On HB2C, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. Multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the HB2C shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the HB2C team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2C\nQ: I want to redo HB2C data processing.\nA: On HB2C, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. Multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the HB2C shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the HB2C team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2C\nQ: Rerun my HB2C data analysis.\nA: On HB2C, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. Multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the HB2C shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the HB2C team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2C\nQ: Show me how to rerun HB2C processing.\nA: On HB2C, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. Multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the HB2C shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the HB2C team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2C\nQ: I need to process my HB2C data. Give me some information.\nA: Normally, the HB2C autoreduction routine will take care of the data processing and reduced data can be found at `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. With the autoreduction routine for HB2C, multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the HB2C shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the HB2C team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2C\nQ: How do I process HB2C data?\nA: Normally, the HB2C autoreduction routine will take care of the data processing and reduced data can be found at `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. With the autoreduction routine for HB2C, multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the HB2C shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the HB2C team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2C\nQ: I want to process my HB2C measurements.\nA: Normally, the HB2C autoreduction routine will take care of the data processing and reduced data can be found at `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. With the autoreduction routine for HB2C, multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the HB2C shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the HB2C team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2C\nQ: Tell me about HB2C data processing.\nA: Normally, the HB2C autoreduction routine will take care of the data processing and reduced data can be found at `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. With the autoreduction routine for HB2C, multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the HB2C shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the HB2C team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2C\nQ: How can I process data from HB2C?\nA: Normally, the HB2C autoreduction routine will take care of the data processing and reduced data can be found at `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. With the autoreduction routine for HB2C, multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the HB2C shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the HB2C team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2C\nQ: I need help with HB2C data reduction.\nA: Normally, the HB2C autoreduction routine will take care of the data processing and reduced data can be found at `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. With the autoreduction routine for HB2C, multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the HB2C shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the HB2C team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2C\nQ: Process my HB2C data.\nA: Normally, the HB2C autoreduction routine will take care of the data processing and reduced data can be found at `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. With the autoreduction routine for HB2C, multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the HB2C shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the HB2C team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2C\nQ: What's the procedure for HB2C data processing?\nA: Normally, the HB2C autoreduction routine will take care of the data processing and reduced data can be found at `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. With the autoreduction routine for HB2C, multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the HB2C shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the HB2C team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2C\nQ: I want to reduce HB2C data.\nA: Normally, the HB2C autoreduction routine will take care of the data processing and reduced data can be found at `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. With the autoreduction routine for HB2C, multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the HB2C shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the HB2C team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2C\nQ: Guide me through HB2C data processing.\nA: Normally, the HB2C autoreduction routine will take care of the data processing and reduced data can be found at `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. With the autoreduction routine for HB2C, multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the HB2C shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the HB2C team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2C\nQ: How to handle HB2C data reduction?\nA: Normally, the HB2C autoreduction routine will take care of the data processing and reduced data can be found at `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. With the autoreduction routine for HB2C, multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the HB2C shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the HB2C team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2C\nQ: I need information on HB2C data processing.\nA: Normally, the HB2C autoreduction routine will take care of the data processing and reduced data can be found at `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. With the autoreduction routine for HB2C, multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the HB2C shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the HB2C team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2C\nQ: Explain HB2C data processing steps.\nA: Normally, the HB2C autoreduction routine will take care of the data processing and reduced data can be found at `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. With the autoreduction routine for HB2C, multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the HB2C shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the HB2C team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2C\nQ: How do I reduce my HB2C data?\nA: Normally, the HB2C autoreduction routine will take care of the data processing and reduced data can be found at `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. With the autoreduction routine for HB2C, multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the HB2C shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the HB2C team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2C\nQ: Tell me about processing data on HB2C.\nA: Normally, the HB2C autoreduction routine will take care of the data processing and reduced data can be found at `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. With the autoreduction routine for HB2C, multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the HB2C shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the HB2C team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND^2\nQ: I need to rerun the processing for my WAND^2 data. Give me some information.\nA: On WAND^2, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. Multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND^2 shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND^2 team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND^2\nQ: I want to reprocess my WAND^2 data.\nA: On WAND^2, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. Multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND^2 shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND^2 team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND^2\nQ: How do I rerun WAND^2 data processing?\nA: On WAND^2, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. Multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND^2 shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND^2 team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND^2\nQ: I need to rerun WAND^2 autoreduction.\nA: On WAND^2, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. Multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND^2 shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND^2 team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND^2\nQ: Reprocess WAND^2 data for me.\nA: On WAND^2, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. Multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND^2 shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND^2 team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND^2\nQ: How can I rerun the processing on WAND^2?\nA: On WAND^2, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. Multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND^2 shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND^2 team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND^2\nQ: I want to rerun my WAND^2 measurements.\nA: On WAND^2, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. Multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND^2 shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND^2 team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND^2\nQ: Tell me how to rerun WAND^2 data reduction.\nA: On WAND^2, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. Multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND^2 shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND^2 team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND^2\nQ: I need help rerunning WAND^2 processing.\nA: On WAND^2, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. Multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND^2 shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND^2 team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND^2\nQ: Rerun WAND^2 data processing steps.\nA: On WAND^2, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. Multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND^2 shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND^2 team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND^2\nQ: Guide me through rerunning WAND^2 autoreduction.\nA: On WAND^2, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. Multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND^2 shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND^2 team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND^2\nQ: How to reprocess WAND^2 measurements?\nA: On WAND^2, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. Multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND^2 shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND^2 team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND^2\nQ: I want to redo WAND^2 data processing.\nA: On WAND^2, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. Multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND^2 shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND^2 team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND^2\nQ: Rerun my WAND^2 data analysis.\nA: On WAND^2, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. Multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND^2 shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND^2 team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND^2\nQ: Show me how to rerun WAND^2 processing.\nA: On WAND^2, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. Multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND^2 shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND^2 team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND^2\nQ: I need to process my WAND^2 data. Give me some information.\nA: Normally, the WAND^2 autoreduction routine will take care of the data processing and reduced data can be found at `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. With the autoreduction routine for WAND^2, multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND^2 shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND^2 team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND^2\nQ: How do I process WAND^2 data?\nA: Normally, the WAND^2 autoreduction routine will take care of the data processing and reduced data can be found at `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. With the autoreduction routine for WAND^2, multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND^2 shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND^2 team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND^2\nQ: I want to process my WAND^2 measurements.\nA: Normally, the WAND^2 autoreduction routine will take care of the data processing and reduced data can be found at `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. With the autoreduction routine for WAND^2, multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND^2 shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND^2 team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND^2\nQ: Tell me about WAND^2 data processing.\nA: Normally, the WAND^2 autoreduction routine will take care of the data processing and reduced data can be found at `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. With the autoreduction routine for WAND^2, multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND^2 shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND^2 team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND^2\nQ: How can I process data from WAND^2?\nA: Normally, the WAND^2 autoreduction routine will take care of the data processing and reduced data can be found at `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. With the autoreduction routine for WAND^2, multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND^2 shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND^2 team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND^2\nQ: I need help with WAND^2 data reduction.\nA: Normally, the WAND^2 autoreduction routine will take care of the data processing and reduced data can be found at `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. With the autoreduction routine for WAND^2, multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND^2 shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND^2 team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND^2\nQ: Process my WAND^2 data.\nA: Normally, the WAND^2 autoreduction routine will take care of the data processing and reduced data can be found at `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. With the autoreduction routine for WAND^2, multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND^2 shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND^2 team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND^2\nQ: What's the procedure for WAND^2 data processing?\nA: Normally, the WAND^2 autoreduction routine will take care of the data processing and reduced data can be found at `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. With the autoreduction routine for WAND^2, multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND^2 shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND^2 team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND^2\nQ: I want to reduce WAND^2 data.\nA: Normally, the WAND^2 autoreduction routine will take care of the data processing and reduced data can be found at `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. With the autoreduction routine for WAND^2, multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND^2 shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND^2 team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND^2\nQ: Guide me through WAND^2 data processing.\nA: Normally, the WAND^2 autoreduction routine will take care of the data processing and reduced data can be found at `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. With the autoreduction routine for WAND^2, multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND^2 shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND^2 team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND^2\nQ: How to handle WAND^2 data reduction?\nA: Normally, the WAND^2 autoreduction routine will take care of the data processing and reduced data can be found at `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. With the autoreduction routine for WAND^2, multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND^2 shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND^2 team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND^2\nQ: I need information on WAND^2 data processing.\nA: Normally, the WAND^2 autoreduction routine will take care of the data processing and reduced data can be found at `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. With the autoreduction routine for WAND^2, multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND^2 shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND^2 team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND^2\nQ: Explain WAND^2 data processing steps.\nA: Normally, the WAND^2 autoreduction routine will take care of the data processing and reduced data can be found at `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. With the autoreduction routine for WAND^2, multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND^2 shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND^2 team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND^2\nQ: How do I reduce my WAND^2 data?\nA: Normally, the WAND^2 autoreduction routine will take care of the data processing and reduced data can be found at `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. With the autoreduction routine for WAND^2, multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND^2 shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND^2 team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND^2\nQ: Tell me about processing data on WAND^2.\nA: Normally, the WAND^2 autoreduction routine will take care of the data processing and reduced data can be found at `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. With the autoreduction routine for WAND^2, multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND^2 shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND^2 team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND\nQ: I need to rerun the processing for my WAND data. Give me some information.\nA: On WAND, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. Multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND\nQ: I want to reprocess my WAND data.\nA: On WAND, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. Multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND\nQ: How do I rerun WAND data processing?\nA: On WAND, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. Multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND\nQ: I need to rerun WAND autoreduction.\nA: On WAND, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. Multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND\nQ: Reprocess WAND data for me.\nA: On WAND, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. Multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND\nQ: How can I rerun the processing on WAND?\nA: On WAND, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. Multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND\nQ: I want to rerun my WAND measurements.\nA: On WAND, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. Multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND\nQ: Tell me how to rerun WAND data reduction.\nA: On WAND, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. Multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND\nQ: I need help rerunning WAND processing.\nA: On WAND, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. Multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND\nQ: Rerun WAND data processing steps.\nA: On WAND, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. Multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND\nQ: Guide me through rerunning WAND autoreduction.\nA: On WAND, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. Multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND\nQ: How to reprocess WAND measurements?\nA: On WAND, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. Multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND\nQ: I want to redo WAND data processing.\nA: On WAND, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. Multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND\nQ: Rerun my WAND data analysis.\nA: On WAND, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. Multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND\nQ: Show me how to rerun WAND processing.\nA: On WAND, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. Multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND\nQ: I need to process my WAND data. Give me some information.\nA: Normally, the WAND autoreduction routine will take care of the data processing and reduced data can be found at `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. With the autoreduction routine for WAND, multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND\nQ: How do I process WAND data?\nA: Normally, the WAND autoreduction routine will take care of the data processing and reduced data can be found at `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. With the autoreduction routine for WAND, multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND\nQ: I want to process my WAND measurements.\nA: Normally, the WAND autoreduction routine will take care of the data processing and reduced data can be found at `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. With the autoreduction routine for WAND, multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND\nQ: Tell me about WAND data processing.\nA: Normally, the WAND autoreduction routine will take care of the data processing and reduced data can be found at `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. With the autoreduction routine for WAND, multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND\nQ: How can I process data from WAND?\nA: Normally, the WAND autoreduction routine will take care of the data processing and reduced data can be found at `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. With the autoreduction routine for WAND, multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND\nQ: I need help with WAND data reduction.\nA: Normally, the WAND autoreduction routine will take care of the data processing and reduced data can be found at `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. With the autoreduction routine for WAND, multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND\nQ: Process my WAND data.\nA: Normally, the WAND autoreduction routine will take care of the data processing and reduced data can be found at `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. With the autoreduction routine for WAND, multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND\nQ: What's the procedure for WAND data processing?\nA: Normally, the WAND autoreduction routine will take care of the data processing and reduced data can be found at `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. With the autoreduction routine for WAND, multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND\nQ: I want to reduce WAND data.\nA: Normally, the WAND autoreduction routine will take care of the data processing and reduced data can be found at `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. With the autoreduction routine for WAND, multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND\nQ: Guide me through WAND data processing.\nA: Normally, the WAND autoreduction routine will take care of the data processing and reduced data can be found at `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. With the autoreduction routine for WAND, multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND\nQ: How to handle WAND data reduction?\nA: Normally, the WAND autoreduction routine will take care of the data processing and reduced data can be found at `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. With the autoreduction routine for WAND, multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND\nQ: I need information on WAND data processing.\nA: Normally, the WAND autoreduction routine will take care of the data processing and reduced data can be found at `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. With the autoreduction routine for WAND, multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND\nQ: Explain WAND data processing steps.\nA: Normally, the WAND autoreduction routine will take care of the data processing and reduced data can be found at `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. With the autoreduction routine for WAND, multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND\nQ: How do I reduce my WAND data?\nA: Normally, the WAND autoreduction routine will take care of the data processing and reduced data can be found at `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. With the autoreduction routine for WAND, multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: WAND\nQ: Tell me about processing data on WAND.\nA: Normally, the WAND autoreduction routine will take care of the data processing and reduced data can be found at `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`. In case of parameters tweaking and a re-processing is needed, I can provide some information about it. With the autoreduction routine for WAND, multiple folders are included as the output, including `CSV`, `DAT` and `XYE` -- they are fundamentally the same reduced data but with different output formats. Configuration for the autoreduction is contained in parameter files located at dedicated places. In the WAND shared location (`/HFIR/HB2C/shared/autoreduce`), the configuration file `auto_config.json` can be changed according to the parameters tweaking need. The `auto_exp.csv` file contains the information about the normalization runs to be used for the data processing. Only the WAND team members have the permission to change these two files. On the user-level, if changes are to be made, we can go to the IPTS directory, like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce` and edit the file `auto_params.json`. The logic here is, if the user-level configuration file exists, it will take the priority in running the data processing.\n\nTo run the processing for a series of measurements, we can log into the ORNL Analysis cluster (see here, analysis.sns.gov), open a terminal and run `all_wpd 12345 \"10000-10050\"`, where `12345` represents the IPTS number and \"10000-10050\" represents a range of run numbers within that IPTS. Processed data will be saved into something like `/HFIR/HB2C/IPTS-xxxxx/shared/autoreduce`."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2A\nQ: I need to rerun the processing for my HB2A data. Give me some information.\nA: On HB2A, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2A/IPTS-xxxxx/shared/autoreduce`. In most cases, autoreduction should handle the data processing seamlessly. In some rare cases when the autoreduction is not giving reasonable output, please get in touch with the team (https://neutrons.ornl.gov/powder/team)."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2A\nQ: I want to reprocess my HB2A data.\nA: On HB2A, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2A/IPTS-xxxxx/shared/autoreduce`. In most cases, autoreduction should handle the data processing seamlessly. In some rare cases when the autoreduction is not giving reasonable output, please get in touch with the team (https://neutrons.ornl.gov/powder/team)."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2A\nQ: How do I rerun HB2A data processing?\nA: On HB2A, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2A/IPTS-xxxxx/shared/autoreduce`. In most cases, autoreduction should handle the data processing seamlessly. In some rare cases when the autoreduction is not giving reasonable output, please get in touch with the team (https://neutrons.ornl.gov/powder/team)."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2A\nQ: I need to rerun HB2A autoreduction.\nA: On HB2A, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2A/IPTS-xxxxx/shared/autoreduce`. In most cases, autoreduction should handle the data processing seamlessly. In some rare cases when the autoreduction is not giving reasonable output, please get in touch with the team (https://neutrons.ornl.gov/powder/team)."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2A\nQ: Reprocess HB2A data for me.\nA: On HB2A, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2A/IPTS-xxxxx/shared/autoreduce`. In most cases, autoreduction should handle the data processing seamlessly. In some rare cases when the autoreduction is not giving reasonable output, please get in touch with the team (https://neutrons.ornl.gov/powder/team)."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2A\nQ: How can I rerun the processing on HB2A?\nA: On HB2A, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2A/IPTS-xxxxx/shared/autoreduce`. In most cases, autoreduction should handle the data processing seamlessly. In some rare cases when the autoreduction is not giving reasonable output, please get in touch with the team (https://neutrons.ornl.gov/powder/team)."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2A\nQ: I want to rerun my HB2A measurements.\nA: On HB2A, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2A/IPTS-xxxxx/shared/autoreduce`. In most cases, autoreduction should handle the data processing seamlessly. In some rare cases when the autoreduction is not giving reasonable output, please get in touch with the team (https://neutrons.ornl.gov/powder/team)."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2A\nQ: Tell me how to rerun HB2A data reduction.\nA: On HB2A, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2A/IPTS-xxxxx/shared/autoreduce`. In most cases, autoreduction should handle the data processing seamlessly. In some rare cases when the autoreduction is not giving reasonable output, please get in touch with the team (https://neutrons.ornl.gov/powder/team)."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2A\nQ: I need help rerunning HB2A processing.\nA: On HB2A, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2A/IPTS-xxxxx/shared/autoreduce`. In most cases, autoreduction should handle the data processing seamlessly. In some rare cases when the autoreduction is not giving reasonable output, please get in touch with the team (https://neutrons.ornl.gov/powder/team)."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2A\nQ: Rerun HB2A data processing steps.\nA: On HB2A, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2A/IPTS-xxxxx/shared/autoreduce`. In most cases, autoreduction should handle the data processing seamlessly. In some rare cases when the autoreduction is not giving reasonable output, please get in touch with the team (https://neutrons.ornl.gov/powder/team)."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2A\nQ: Guide me through rerunning HB2A autoreduction.\nA: On HB2A, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2A/IPTS-xxxxx/shared/autoreduce`. In most cases, autoreduction should handle the data processing seamlessly. In some rare cases when the autoreduction is not giving reasonable output, please get in touch with the team (https://neutrons.ornl.gov/powder/team)."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2A\nQ: How to reprocess HB2A measurements?\nA: On HB2A, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2A/IPTS-xxxxx/shared/autoreduce`. In most cases, autoreduction should handle the data processing seamlessly. In some rare cases when the autoreduction is not giving reasonable output, please get in touch with the team (https://neutrons.ornl.gov/powder/team)."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2A\nQ: I want to redo HB2A data processing.\nA: On HB2A, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2A/IPTS-xxxxx/shared/autoreduce`. In most cases, autoreduction should handle the data processing seamlessly. In some rare cases when the autoreduction is not giving reasonable output, please get in touch with the team (https://neutrons.ornl.gov/powder/team)."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2A\nQ: Rerun my HB2A data analysis.\nA: On HB2A, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2A/IPTS-xxxxx/shared/autoreduce`. In most cases, autoreduction should handle the data processing seamlessly. In some rare cases when the autoreduction is not giving reasonable output, please get in touch with the team (https://neutrons.ornl.gov/powder/team)."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2A\nQ: Show me how to rerun HB2A processing.\nA: On HB2A, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2A/IPTS-xxxxx/shared/autoreduce`. In most cases, autoreduction should handle the data processing seamlessly. In some rare cases when the autoreduction is not giving reasonable output, please get in touch with the team (https://neutrons.ornl.gov/powder/team)."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2A\nQ: I need to process my HB2A data. Give me some information.\nA: On HB2A, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2A/IPTS-xxxxx/shared/autoreduce`. In most cases, autoreduction should handle the data processing seamlessly. In some rare cases when the autoreduction is not giving reasonable output, please get in touch with the team (https://neutrons.ornl.gov/powder/team)."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2A\nQ: How do I process HB2A data?\nA: On HB2A, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2A/IPTS-xxxxx/shared/autoreduce`. In most cases, autoreduction should handle the data processing seamlessly. In some rare cases when the autoreduction is not giving reasonable output, please get in touch with the team (https://neutrons.ornl.gov/powder/team)."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2A\nQ: I want to process my HB2A measurements.\nA: On HB2A, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2A/IPTS-xxxxx/shared/autoreduce`. In most cases, autoreduction should handle the data processing seamlessly. In some rare cases when the autoreduction is not giving reasonable output, please get in touch with the team (https://neutrons.ornl.gov/powder/team)."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2A\nQ: Tell me about HB2A data processing.\nA: On HB2A, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2A/IPTS-xxxxx/shared/autoreduce`. In most cases, autoreduction should handle the data processing seamlessly. In some rare cases when the autoreduction is not giving reasonable output, please get in touch with the team (https://neutrons.ornl.gov/powder/team)."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2A\nQ: How can I process data from HB2A?\nA: On HB2A, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2A/IPTS-xxxxx/shared/autoreduce`. In most cases, autoreduction should handle the data processing seamlessly. In some rare cases when the autoreduction is not giving reasonable output, please get in touch with the team (https://neutrons.ornl.gov/powder/team)."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2A\nQ: I need help with HB2A data reduction.\nA: On HB2A, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2A/IPTS-xxxxx/shared/autoreduce`. In most cases, autoreduction should handle the data processing seamlessly. In some rare cases when the autoreduction is not giving reasonable output, please get in touch with the team (https://neutrons.ornl.gov/powder/team)."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2A\nQ: Process my HB2A data.\nA: On HB2A, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2A/IPTS-xxxxx/shared/autoreduce`. In most cases, autoreduction should handle the data processing seamlessly. In some rare cases when the autoreduction is not giving reasonable output, please get in touch with the team (https://neutrons.ornl.gov/powder/team)."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2A\nQ: What's the procedure for HB2A data processing?\nA: On HB2A, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2A/IPTS-xxxxx/shared/autoreduce`. In most cases, autoreduction should handle the data processing seamlessly. In some rare cases when the autoreduction is not giving reasonable output, please get in touch with the team (https://neutrons.ornl.gov/powder/team)."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2A\nQ: I want to reduce HB2A data.\nA: On HB2A, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2A/IPTS-xxxxx/shared/autoreduce`. In most cases, autoreduction should handle the data processing seamlessly. In some rare cases when the autoreduction is not giving reasonable output, please get in touch with the team (https://neutrons.ornl.gov/powder/team)."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2A\nQ: Guide me through HB2A data processing.\nA: On HB2A, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2A/IPTS-xxxxx/shared/autoreduce`. In most cases, autoreduction should handle the data processing seamlessly. In some rare cases when the autoreduction is not giving reasonable output, please get in touch with the team (https://neutrons.ornl.gov/powder/team)."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2A\nQ: How to handle HB2A data reduction?\nA: On HB2A, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2A/IPTS-xxxxx/shared/autoreduce`. In most cases, autoreduction should handle the data processing seamlessly. In some rare cases when the autoreduction is not giving reasonable output, please get in touch with the team (https://neutrons.ornl.gov/powder/team)."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2A\nQ: I need information on HB2A data processing.\nA: On HB2A, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2A/IPTS-xxxxx/shared/autoreduce`. In most cases, autoreduction should handle the data processing seamlessly. In some rare cases when the autoreduction is not giving reasonable output, please get in touch with the team (https://neutrons.ornl.gov/powder/team)."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2A\nQ: Explain HB2A data processing steps.\nA: On HB2A, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2A/IPTS-xxxxx/shared/autoreduce`. In most cases, autoreduction should handle the data processing seamlessly. In some rare cases when the autoreduction is not giving reasonable output, please get in touch with the team (https://neutrons.ornl.gov/powder/team)."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2A\nQ: How do I reduce my HB2A data?\nA: On HB2A, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2A/IPTS-xxxxx/shared/autoreduce`. In most cases, autoreduction should handle the data processing seamlessly. In some rare cases when the autoreduction is not giving reasonable output, please get in touch with the team (https://neutrons.ornl.gov/powder/team)."}
{"text": "Scope: Instrument data processing\nCategory: Data Reduction\nInstrument: HB2A\nQ: Tell me about processing data on HB2A.\nA: On HB2A, autoreduction service is available to process the data automatically. Processed data would be saved into location like `/HFIR/HB2A/IPTS-xxxxx/shared/autoreduce`. In most cases, autoreduction should handle the data processing seamlessly. In some rare cases when the autoreduction is not giving reasonable output, please get in touch with the team (https://neutrons.ornl.gov/powder/team)."}
